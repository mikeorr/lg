<!DOCTYPE html PUBLIC '-//W3C//DTD XHTML 1.0 Transitional//EN'
		 'http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd'>
<html xmlns='http://www.w3.org/1999/xhtml' lang='utf-8' xml:lang='utf-8'>
<head>
<title>Apertium 2 cent tip: how to add analysis and generation of unknown words, and *why you shouldn't*</title>
<meta http-equiv='Content-Type; charset=utf-8' />
<link rel='stylesheet' type='text/css' href='../../../lg.css' />
</head>
<body>
<a href="../../../"><img alt="Linux Gazette" src="../../../gx/2003/newlogo-blank-200-gold2.jpg" id="logo" /></a><img alt="Tux" src="../../../gx/tux_86x95_indexed.png" id="tux" /><p id="fun">...making Linux just a little more fun!</p><div class='content articlecontent'><a name="top"></a><h3>Apertium 2 cent tip: how to add analysis and generation of unknown words, and *why you shouldn't*</h3>
<p>
<b><p>
Jimmy O'Regan [joregan at gmail.com]

</p>
</b><br />
<b>Thu, 1 Jan 2009 15:27:30 +0000</b>
</p>

<p>
In my article about Apertium, I promised to follow it up with another
article of a more 'HOWTO' nature. And I've been writing it. And
constantly rewriting it, every time somebody asks how to do something
that I think is moronic, to explain why they shouldn't do that... and
I need to accept that people will always want to do stupid things, and
I should just write a HOWTO.
</p>

<p>
Anyway... recently, someone asked how to implement generation of
unknown words. There are only two reasons I can think of, why someone
would want this: either they have words in the bilingual dictionary
that they don't have in the monolingual dictionary, or they want to
use it in conjunction with morphological guessing.
</p>

<p>
In general, the usual method used in Apertium's translators is, if we
don't know the word, we don't try to translate it -- we're honest
about it, essentially. Apertium has an option to mark unknown words,
which we generally recommend that people use. It doesn't cover
'hidden' unknown words, where the same word an be two different parts
of speech--we're looking into how to attempt that. One result of this,
is that before a release, we specifically remove some words from the
monolingual dictionary, if we can't add a translation.
</p>

<p>
Anyway, in the first case, we generally write scripts to automate
adding those words to the bidix. One plus of this is that it can be
manually checked afterwards, and fixed. Another is that, by adding the
word to the monolingual dictionary, we can also analyse it: we
generally try to make bilingual translators, but sometimes we can only
make a single direction translator--but we still have the option of
adding the other direction later. And, as our translators are open
source, it increases the amount of freely available linguistic data to
do so, so it's a win all round.
</p>

<p>
The latter case, of also using a mophological guesser, is one source
of some of the worst translations out there. For example, at the
moment, I'm translating a short story by Adam Mickiewicz, which
contains the phrase 'tu i owdzie', which is either a misspelling of
'tu i ówdzie' ('here and there') or an old form, or typesetting
error[1], but in any case, the word 'owdzie' does not exist in the
modern Polish language.
</p>

<p>
Translatica, the leading Polish-English translator, gave: "here and he
is owdzying"
</p>

<p>
Now, if I knew nothing of Polish, that would send me scrambling to the
English dictionary, to search for the non-existant verb 'to owdzy'.
</p>

<p>
(Google gave: "here said". SMT is a great idea, in theory, but in
practice[2] has the potential to give translations that bear no
resemblance to the original meaning of the source text. Google's own
method of 'augmenting' SMT by extracting correlating phrase pairs
based on a pivot language also leads to extra ambiguities[3])
</p>

<p>
Anyway. The tip, for anyone who still wants to try it
</p>

<p>
Apetium's dictionaries can have a limited subset of regular
expressions; these can be used by someone who wishes to have both
analysis and generation of unknown words. The &lt;re&gt; tag can be placed
before the &lt;par&gt; tag, so the entry:
</p>

<pre>
&lt;e&gt;
  &lt;re&gt;[a-z]*&lt;/re&gt;
  &lt;par n="accept__vblex"/&gt;
&lt;/e&gt;
</pre>

<p>
will accept, and generate, any otherwise unknown word with the set of
endings represented by the paradigm for the verb 'accept', -s, -ed,
-ing, -0, etc. That gets more complicated when you want to do the same
with verbs like 'live', or 'plug', but judicious use of regexes should
get around that. It's still a bad idea, though, and if anyone tries
this and has poor results and for some reason feels compelled to tell
me about it, expect only 'I told you so' <img src="../gx/smile.png" alt=":)">
</p>

<p>
[1] I ORC'd and proofread the text for Project Gutenberg; that's what
appears in the original text.
</p>

<p>
[2] Word reordering, case restoration, punctuation restoration, etc.
are typically handled in an SMT system in a way that is functionally
similar to the translation process, by scoring the phrases generated
by these stages against a statistical model, which can lead to words
being replaced, replacing a correct translation with an incorrect one
that happens to have better punctuation, etc.
</p>

<p>
[3] The French 'Je viens de manger' ('I have just eaten') translated
to 'Ja po prostu zjeść' ('I simply to eat'; 'po prostu zjedz!' is the
equivalent of 'just eat it!' ) in Polish, because of the ambiguity of
'just' in English, which doesn't exist between French and Polish
(that's today's translation; before it said 'mam tylko jeść' 'I have
only to eat', mixing another ambiguity of 'just' in English, 'I have
just five eggs').
</p>

<p>

</p>
<br /><a href="#top">Top</a>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../lg_tips.html#mb-apertium_2_cent_tip__how_to_add_analysis_and_generation_of_unknown_words_and_why_you_shouldn_t">Back</a><hr width="50%" align="left" /><p><br /></p><p>
<b><p>
Jimmy O'Regan [joregan at gmail.com]

</p>
</b><br />
<b>Thu, 1 Jan 2009 15:35:57 +0000</b>
</p>

<p>
2009/1/1 Jimmy O'Regan &lt;joregan@gmail.com&gt;:
</p>

<pre>
&gt; In general, the usual method used in Apertium's translators is, if we
&gt; don't know the word, we don't try to translate it -- we're honest
&gt; about it, essentially. Apertium has an option to mark unknown words,
&gt; which we generally recommend that people use. It doesn't cover
&gt; 'hidden' unknown words, where the same word an be two different parts
</pre>

<p>
<strong>can</strong> be... I can only imagine how poorly that would translate <img src="../gx/smile.png" alt=":)">
</p>


<pre>
&gt; Anyway, in the first case, we generally write scripts to automate
&gt; adding those words to the bidix. One plus of this is that it can be
</pre>

<p>
adding those words <strong>from</strong> the bidix, to the monodix.
</p>

<p>

</p>
<br /><a href="#top">Top</a>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../lg_tips.html#mb-apertium_2_cent_tip__how_to_add_analysis_and_generation_of_unknown_words_and_why_you_shouldn_t">Back</a><hr width="50%" align="left" /><p><br /></p><p>
<b><p>
Ben Okopnik [ben at linuxgazette.net]

</p>
</b><br />
<b>Thu, 1 Jan 2009 11:06:39 -0500</b>
</p>

<p>
On Thu, Jan 01, 2009 at 03:35:57PM +0000, Jimmy O'Regan wrote:
</p>

<pre>
&gt; 2009/1/1 Jimmy O'Regan &lt;joregan@gmail.com&gt;:
&gt; &gt; In general, the usual method used in Apertium's translators is, if we
&gt; &gt; don't know the word, we don't try to translate it -- we're honest
&gt; &gt; about it, essentially. Apertium has an option to mark unknown words,
&gt; &gt; which we generally recommend that people use. It doesn't cover
&gt; &gt; 'hidden' unknown words, where the same word an be two different parts
&gt; 
&gt; <strong>can</strong> be... I can only imagine how poorly that would translate <img src="../gx/smile.png" alt=":)">
</pre>

<p>
That would be the major downfall of machine translation: the underlying
assumption (which pretty much <em>has</em> to be that way) is that the input
makes sense in the first place. Misspellings, of course, void that: the
above is an instant - you might even say automatic and thus invisible -
correction for a human, but an insoluble problem for a machine.
</p>

<p>
Until someone comes up with systems that can handle context, on a fairly
broad scale, mechanical translation must perforce remain limited. And
even then...
</p>

<pre>
"Prostitutes appeal to pope"
"Queen Mary having bottom scraped"
"Milk drinkers are turning to powder"
"I saw the Alps flying to Romania"
"The horse raced past the barn fell"
"Time flies" "You can't; they move too fast"
"Cheney hunts quail; companions duck"
"Drunk gets nine months in violin case"
</pre>

<p>
<img src="../gx/smile.png" alt=":)">
</p>


<pre>-- 
* Ben Okopnik * Editor-in-Chief, Linux Gazette * <a href='http://LinuxGazette.NET'>http://LinuxGazette.NET</a> *
</pre>

<p>

</p>
<br /><a href="#top">Top</a>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../lg_tips.html#mb-apertium_2_cent_tip__how_to_add_analysis_and_generation_of_unknown_words_and_why_you_shouldn_t">Back</a><hr width="50%" align="left" /><p><br /></p><p>
<b><p>
Jimmy O'Regan [joregan at gmail.com]

</p>
</b><br />
<b>Thu, 1 Jan 2009 19:46:17 +0000</b>
</p>

<p>
2009/1/1 Ben Okopnik &lt;ben@linuxgazette.net&gt;:
</p>

<pre>
&gt; On Thu, Jan 01, 2009 at 03:35:57PM +0000, Jimmy O'Regan wrote:
&gt;&gt; 2009/1/1 Jimmy O'Regan &lt;joregan@gmail.com&gt;:
&gt;&gt; &gt; In general, the usual method used in Apertium's translators is, if we
&gt;&gt; &gt; don't know the word, we don't try to translate it -- we're honest
&gt;&gt; &gt; about it, essentially. Apertium has an option to mark unknown words,
&gt;&gt; &gt; which we generally recommend that people use. It doesn't cover
&gt;&gt; &gt; 'hidden' unknown words, where the same word an be two different parts
&gt;&gt;
&gt;&gt; <strong>can</strong> be... I can only imagine how poorly that would translate <img src="../gx/smile.png" alt=":)">
&gt;
&gt; That would be the major downfall of machine translation: the underlying
&gt; assumption (which pretty much <em>has</em> to be that way) is that the input
&gt; makes sense in the first place. Misspellings, of course, void that: the
&gt; above is an instant - you might even say automatic and thus invisible -
&gt; correction for a human, but an insoluble problem for a machine.
&gt;
</pre>

<p>
Misspellings, orthographic variations in different regions (our
Spanish-English translator still has a curious mix of American and
British spellings), false derivations (we had an example of that here,
recently <img src="../gx/smile.png" alt=":)">, archaisms, the list goes on and on. Even the presence or
absence of punctuation can be significant.
</p>


<pre>
&gt; Until someone comes up with systems that can handle context, on a fairly
&gt; broad scale, mechanical translation must perforce remain limited.
</pre>

<p>
Nice phrase that, 'mechanical translation': it equally covers machine
translation and, say, the collected works of Jeremiah Curtin[1] and
his ilk <img src="../gx/smile.png" alt=":)">
</p>

<p>
Semantic based translation seemed more or less abandoned, but I see
signs of it making a comeback: a paper I read recently more or less
said that the reason attempts to plug systems like WordNet into
machine translators hasn't yielded significantly better results is
that it was not approached in the correct manner (all of the prior
research in the area was wrong <img src="../gx/smile.png" alt=":)">; GramTrans make heavy use of
semantic knowledge in their translators[2].
</p>

<p>
Apertium has a module called 'lextor' that uses statistically
collected co-occurrences to perform lexical selection, but I don't
like trusting to statistics anything that can be manually specified
(our part of speech tagger is also statistically based, but it also
accepts rules). I'm writing a new module that's strictly rule based --
because I'm primarily interested in trying to properly translate
prepositions in relation to verbs, and lextor specifically ignores
prepositions (they would <strong>really</strong> screw up the statistics <img src="../gx/smile.png" alt=":)"> -- but it
also requires changes to the main rule engine, and possibly extending
the stream format, which I'd prefer to avoid.
</p>

<p>
The most promising development in SMT is the Berkeley aligner, which
is open source: <a href='http://code.google.com/p/berkeleyaligner/'>http://code.google.com/p/berkeleyaligner/</a> Instead of
blindly trying to align n-grams, it aligns elements of parse trees.
(Google have done some work in trying to do something similar, but
they've had some difficulty in retrofitting parse trees to the n-grams
they already have).
</p>


<pre>
&gt; And
&gt; even then...
&gt;
&gt; "Prostitutes appeal to pope"
&gt; "Queen Mary having bottom scraped"
&gt; "Milk drinkers are turning to powder"
&gt; "I saw the Alps flying to Romania"
&gt; "The horse raced past the barn fell"
&gt; "Time flies" "You can't; they move too fast"
&gt; "Cheney hunts quail; companions duck"
&gt; "Drunk gets nine months in violin case"
&gt;
&gt; <img src="../gx/smile.png" alt=":)">
&gt;
</pre>

<p>
Those all remind me that there's one thing a human translator can do
that a computer program never can: add a footnote <img src="../gx/smile.png" alt=":)">
</p>

<p>
If you'll forgive my choice of example, 'te przeklęte Moskale' --
'those cursed Muscovites'. That's an easy, word to word translation,
but: in Polish, a distinction is made in the plural between human
males and anything else: the correct form should be 'ci przeklęci
Moskali': using the incorrect form is possibly intended to either show
that the speaker has been poorly educated, or that he intends to
intensify the insult by speaking of the Muscovites as 'non-men'. I've
been assured that in the time the story was set[3], that would have
been grammatically correct, but the rest of the text contradicts that.
</p>

<p>
[1] Douglas Hyde wrote of him: "Mr. Curtin tells us that he has taken
his tales from the old Gaelic-speaking men; but he must have done so
through the awkward medium of an interpreter, for his ignorance of the
commonest Irish words is as startling as Lady Wilde's." Curtin is more
famous for his bad translations of Polish stories, though.
</p>

<p>
[2] <a href='http://gramtrans.com/'>http://gramtrans.com/</a>
Their data is proprietary, but their semantic engine, CG, is open
source, and used in a few translation modules in Apertium - we don't
use it to its full extent yet, but we have an experimental translator
that does (between two dialects of the Sami language). The main
developer of our Esperanto-English translator is friends with their
main developer, who has been quite helpful.
</p>

<p>
[3] The Battle of Stoczek, the first major battle of the November
Uprising of 1830.
</p>

<p>

</p>
<br /><a href="#top">Top</a>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../lg_tips.html#mb-apertium_2_cent_tip__how_to_add_analysis_and_generation_of_unknown_words_and_why_you_shouldn_t">Back</a><hr width="50%" align="left" /><p><br /></p></div>
</body>
</html>