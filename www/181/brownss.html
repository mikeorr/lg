<!DOCTYPE html
	PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
	 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="utf-8" xml:lang="utf-8">
<head>
<title>Simple lip-sync animations in Linux LG #181</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" href="../lg.css" type="text/css" media="screen, projection"  />
<link rel="alternate" type="application/rss+xml" title="LG RSS" href="../lg.rss" />
<link rel="alternate" type="application/rdf+xml" title="LG RDF" href="../lg.rdf" />
<!-- link rel="alternate" type="application/atom+xml" title="LG Atom" href="lg.atom.xml" / -->
<link rel="shortcut icon" href="../favicon.ico" />

<style type="text/css" media="screen, projection">
<!--

-->
</style>

</head>
<body>

<a href="../">
<img src="../gx/2003/newlogo-blank-200-gold2.jpg" id="logo" alt="Linux Gazette"/>
</a>
<p id="fun">...making Linux just a little more fun!</p>

<div id="navigation">
<table summary="masthead" width="100%">
<tr>
<td align="center" colspan="3" style="font-size: 10px; font-weight: bold">
<a href="../index.html">Home</a>
<a href="http://linuxgazette.net">Main Site</a>
<a href="../faq/index.html">FAQ</a>

<a href="../lg_index.html">Site Map</a>
<a href="../mirrors.html">Mirrors</a>
<a href="../mirrors.html">Translations</a>
<a href="../search.html">Search</a>
<a href="../archives.html">Archives</a>
<a href="../authors/index.html">Authors</a>
<a href="http://lists.linuxgazette.net/listinfo.cgi">Mailing Lists</a>
<a href="../jobs.html">Join Us!</a>
<a href="../contact.html">Contact Us</a>

<hr width="99%" style="border: 1px inset #000033">
</td>
</tr>
<tr>
<td width="40%" align="left" style="font-size: 10px; font-weight: bold">
The Free International Online Linux Monthly
</td>
<td width="20%" align="center" style="font-size: 10px; font-weight: bold">
ISSN: 1934-371X
</td>
<td width="40%" align="right" style="font-size: 10px; font-weight: bold">
Main site: <a href="http://linuxgazette.net">http://linuxgazette.net</a> 
</td>
</table>
</div>


<div id="breadcrumbs1">

<a href="../index.html">Home</a> &gt; 
<a href="index.html">December 2010 (#181)</a> &gt; 
Article

</div>

<div class="articlecontent1">
<div class="content">

<div id="previousnexttop">
<A HREF="lg_bytes.html" >&lt;-- prev</A> | <A HREF="grebler.html" >next --&gt;</A>
</div>

<h1>Simple lip-sync animations in Linux</h1>
<p id="by"><b>By <a href="../authors/brownss.html">Silas Brown</a></b></p>

<p>Commercial Windows programs like CrazyTalk
let you turn any image into an animation that
lip-syncs to speech audio, so you can create
talking characters.  In this article, I will
outline how to do this using nothing but free
Linux tools.  The result is more basic but it
should be adequate in many cases.</p>

<h3>Step 1: Create about 3 frames in The GIMP</h3>

<p>Start with the image you want to animate in
PNG format, preferably at a fairly low
resolution so that the face fits in 100x100
pixels or so (which saves you from making too
many frames).  The face should have a
fully-closed mouth initially, so let's call the
image <tt>mouth-closed.png</tt>.  Load it into
The GIMP (<tt>gimp mouth-closed.png</tt>) and
use the scale drop-down box (on the status bar)
to get it up to 400% or 800% zoom so you can
work with individual pixels. Scroll the image to the
mouth area.</p>

<p>Enable GIMP's Free Select tool, either by
finding it in the toolbox window or by pressing
F.  This tool lets you draw freehand areas of
the image you want to manipulate.  For example,
you can erase an unwanted background to white
by drawing around areas of the background and
pressing Control-X to cut them out.  However,
in this case we want to drag the bottom half of
the mouth down, opening it by one pixel, and
we'll probably want the inside of the mouth to
be black rather than white.  Therefore, it is
important to <strong>set the background colour
to black</strong>.  This can be done, for
example, by using the GIMP toolbox window to
swap the foreground and background colours.</p>

<p>Carefully draw a line that horizontally
traces out where the lips join.  Without
releasing the mouse, drag downward a little and
continue to draw around the entire lower half
of the mouth.  You don't need to worry about
ending on the exact point where you started, as
The GIMP will complete your path with a
straight line if necessary.  If you make a
mistake, click outside the selected area to
cancel it and try again.</p>

<p>When you have the lower half of the mouth
selected, press Control-X to cut it out, and
then press Control-V to paste.  Then drag the
pasted copy so that it is about one pixel below
its original position.  You should now have
about one pixel of black in the mouth, showing
it is partially open.  (I say "about" one pixel
of black, because it won't be a clear-cut black
line; The GIMP will be anti-aliasing it for
you.) Click outside the selected area to cancel
the selection, and go back to 100% zoom to
check how it looks.  Then save the image as
<tt>mouthopen-1.png</tt>.</p>

<p>Now repeat the process to get the mouth
opened by another pixel.  It's better if this
time you don't select quite as far as
the extreme corners of the partially-opened
mouth, because the middle of a mouth moves more
than its corners.  Save the result as
<tt>mouthopen-2.png</tt>.</p>

<p>If you're working in a low enough resolution,
then you should find that those two are enough. 
But you can try making <tt>mouthopen-3.png</tt>
as well if you like, in which case make sure it
is listed in the script below.</p>

<h3>Step 2: Convert the sound's amplitude to an
image sequence</h3>

<p>This is not very professional because the
true shape of a mouth will depend on the vowel
that is being spoken and not just the volume of
the speech, but for light use you might be
surprised how far you can get by simply using
the amplitude.</p>

<p>Because we'll be using a simple Python
script to convert the amplitude to a lip
position, it is very important that the audio
file we start with has <strong>absolutely
no</strong> background noise.  (If you want
background noise in the final result then
you'll have to mix it in <em>after</em> running
the script below.) If the audio file has been
generated by a speech synthesizer
(<tt>espeak</tt> or whatever) then that should
be perfect, but if you are going to record it
then you'd better make sure to record in a very
quiet environment.</p>

<p>We need to make sure that our speech file
(let's call it <tt>speech.wav</tt>) is padded
with at least 3 seconds of silence at the end. 
This is because we'll be using MEncoder later,
and a bug in some versions of MEncoder can
cause the last 3 seconds of audio to be
lost. (You can skip this step if you don't have
a buggy MEncoder, in which case just call the file <tt>padded.wav</tt>.)</p>

<pre>
sox speech.wav padded.wav pad 0.1 3
</pre>

<p>You should now have a file
<tt>padded.wav</tt> with the extra silence in
it.  Next, for our "analytical" purposes, we
convert this to unsigned 8bit 4kHz mono (but
don't throw away the original!) so that we can
read out the amplitudes more easily with a
script.</p>

<pre>
sox padded.wav -1 -u -c 1 -r 4000 -t raw rawfile
</pre>

<p>This should make a file <tt>rawfile</tt>
which the following Python script can use to
convert into an image sequence (actually a
sequence of symbolic links to your frames). 
The Python script will then run
<tt>mencoder</tt> to make the actual
animation.</p>

<pre>
framerate = 10 ; slice=4000/framerate
dat = open("rawfile").read()
frames = []
import os
for i in range(0,len(dat),slice):
    samples = map(lambda x:ord(x)-128,
                  dat[i:i+slice])
    frames.append(max(samples))

pics = ["mouth-closed.png",
        "mouthopen-1.png",
        "mouthopen-2.png"]
max_mouthOpen = len(pics)-1

step = int(max(frames)/(max_mouthOpen*2))
for i in range(len(frames)):
    mouth=min(int(frames[i]/step),max_mouthOpen)
    if i:
        if mouth&gt;frames[i-1]+1:
            mouth=frames[i-1]+1
        elif mouth &lt; frames[i-1]-1:
            mouth=frames[i-1]-1
    else: mouth=0
    frames[i] = mouth
    os.system("ln -s %s frame%09d.png" %
              (pics[mouth],i))

os.system(("mencoder 'mf://frame0*.png' " +
          "-audiofile padded.wav -mf type=png " +
          "-mf fps=%d -oac mp3lame -ovc lavc " +
          "-o animation.avi &amp;&amp; rm frame0*.png")
          % framerate)
</pre>

<p>Make sure there are no files that match the
pattern <tt>frame0*.png</tt> in the current
directory when you run this.  The output is
saved to <tt>animation.avi</tt> which you can
then view in <tt>mplayer</tt>.</p>

<h3>Limitations</h3>

<p>Because this approach opens the mouth by
only a few pixels, the resulting video is
unlikely to scale well.  Rather than try to
scale the video after it has been produced, try
to make sure the original image is of the right
dimensions to start with.</p>

<p>Some versions of MEncoder/MPlayer might not
manage to keep the audio in sync with the video
for long sequences (more than a few seconds). 
A player with a setting like "override AVI
frame rate based on audio" will not have this
problem, and neither does YouTube's uploads
converter.</p>

<br clear="all" />

<table align='center' cellspacing='10'>
<tr>
<td>
<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/181/brownss.html';
digg_title = 'Simple lip-sync animations in Linux';
digg_bodytext = '<p>Commercial Windows programs like CrazyTalk let you turn any image into an animation that lip-syncs to speech audio, so you can create talking characters.  In this article, I will outline how to do this using nothing but free Linux tools.  The result is more basic but it should be adequate in many cases.</p> ';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>
</td>
<td>
<a name="fb_share" type="box_count" href="http://www.facebook.com/sharer.php">Share</a>
<script src="http://static.ak.fbcdn.net/connect.php/js/FB.Share" type="text/javascript"></script>
</td>
<td>
<a href="http://twitter.com/home?status=Currently%20reading:%20http://linuxgazette.net/181/brownss.html%20at%20Linux%20Gazette%20%23linuxgazette" title="Click to share this post on Twitter"><img src="../gx/twitter.png" width="50" height="85" border="0"></a>
</td>
</tr>
</table>


<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:181/brownss.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
<hr>
<p>
<img align="left" alt="[BIO]" src="../gx/authors/brownss.jpg" class="bio">

<em>
Silas Brown is a legally blind computer scientist based in Cambridge UK.
 He has been using heavily-customised versions of Debian Linux since
 1999.
</p>
</em>

<br clear="all">


<!-- *** END author bio *** -->

<div id="articlefooter">

<p>
Copyright &copy; 2010, Silas Brown. Released under the <a
href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>

<p>
Published in Issue 181 of Linux Gazette, December 2010
</p>

</div>

<div id="previousnextbottom">
<A HREF="lg_bytes.html" >&lt;-- prev</A> | <A HREF="grebler.html" >next --&gt;</A>
</div>

</div>
</div>

<script src="http://www.google-analytics.com/urchin.js"
type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-1204316-1";
urchinTracker();
</script>







<img src="../gx/tux_86x95_indexed.png" id="tux" alt="Tux"/>

</body>
</html>

