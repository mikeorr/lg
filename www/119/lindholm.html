
<html>
<head>
<link href="../lg.css" rel="stylesheet" type="text/css" media="screen, projection"  />
<link rel="shortcut icon" href="../favicon.ico" />
<title>Optimizing Website Images with the Littleutils LG #119</title>

<style type="text/css" media="screen, projection">
<!--

-->
</style>

<link rel="alternate" type="application/rss+xml" title="LG RSS" href="lg.rss" />
<link rel="alternate" type="application/rdf+xml" title="LG RDF" href="lg.rdf" />
<link rel="alternate" type="application/atom+xml" title="LG Atom" href="lg.atom.xml" />

</head>

<body>


<img src="../gx/2003/newlogo-blank-200-gold2.jpg" id="logo" alt="Linux Gazette"/>
<p id="fun">...making Linux just a little more fun!</p>


<div class="content articlecontent">

<div id="previousnexttop">
<A HREF="howell.html" >&lt;-- prev</A> | <A HREF="oregan.html" >next --&gt;</A>
</div>



<h1>Optimizing Website Images with the Littleutils</h1>
<p id="by"><b>By <A HREF="../authors/lindholm.html">Brian Lindholm</A></b></p>

<p>

<p>Many years ago, I was taking a LOT of pictures at work with an
early technology digital camera. It provided images in JPEG format.
I was in the process of modifying the images to correct problems
with contrast when I discovered that the camera did a <b>lousy</b>
job of compressing the files.</p>

<p>With the standard software provided by the Independent JPEG
Group (which contains the marvelous <tt>jpegtran</tt> utility), I
could often reduce file size by 50%. Losslessly.  How does this
work? A standard JPEG image uses encoding parameters from
sub-sections of the image. An optimized JPEG image uses
encoding parameters from the <b>entire</b> image.  While
the JPEG algorithm is already lossy, the <tt>jpegtran</tt> utility
preserves the "lossiness" of the original JPEG image exactly. The
new file is thus lossless with respect to the original file.</p>

<p>Here's the command I used:</p>

<pre>
# jpegtran -optimize &lt; original.jpg &gt; optimized.jpg
</pre>

<p>Unfortunately, I'd taken several hundred photos, and processing
them one at a time by hand would have taken forever. So... I wrote
one of my first major shell scripts ever. Once I had it working, I
was able to optimize all of the images in less than ten minutes!
The <tt>opt-jpg</tt> script was born.</p>

<p>A few weeks later, I discovered that "progressive" JPEG images
were sometimes even smaller, but not always. Thus, I modified my
script to try it both ways, and to keep whichever result was
smaller. This made for a trickier script, but the results were
worth it. The <tt>opt-jpg</tt> script was improved.</p>

<p>And even later, an unfortunate event with misnamed BMP images
forced me to add error-checking, so that the script wouldn't modify
non-JPEG files. The <tt>opt-jpg</tt> script became more robust.</p>

<p>Further time resulted in a GIF optimizing script (based on
<tt>gifsicle</tt>) and a PNG optimization script (based on
<tt>pngcrush</tt>) as well, called <tt>opt-gif</tt> and <tt>opt-png</tt>,
respectively. These routines work by colormap reduction, filtering
changes, and other such tricks. You'd be amazed at how many images
out there have a enormous 256-entry colormaps and only use 3 or 4
of the entries.  I recently packaged all of these scripts together
and published them as the <a href=
"http://sourceforge.net/projects/littleutils/"><i>littleutils</i></a>.</p>

<p>While my original motivation in writing these scripts was for
dealing with lousy digital cameras, they are also well-suited for
optimizing all of the graphics on a web site. Why optimize your
graphics? To save hard drive space. To fit more images on your
site. To reduce the amount of time it takes for visitors to your
site to load your pages. The reasons are obvious.</p>

<p>So how does it work? We'll demonstrate with the web pages of the
Linux Gazette itself. First, let's get all of the website files
copied onto a local hard drive. The following command sequence
(under <tt>bash</tt>) will accomplish this:</p>

<pre>
# wget --no-directories --timestamping --recursive --level=1 \
   --accept=.gz http://linuxgazette.net/ftpfiles/
# for i in *.tar.gz ; do tar -xvzf $i ; done
</pre>

<p>And before we begin, we need to establish how much filespace our
current images require:</p>

<pre>
# cd lg/
# find . -name "*.jpg" -print | tar -cf ../jpg.tar -T -
# ls -l ../jpg.tar
# find . -name "*.jpeg" -print | tar -cf ../jpeg.tar -T -
# ls -l ../jpeg.tar
# find . -name "*.JPG" -print | tar -cf ../JPG.tar -T -
# ls -l ../JPG.tar

jpg.tar + jpeg.tar + JPG.tar = 44288000 bytes total

# find . -name "*.gif" -print | tar -cf ../gif.tar -T -
# ls -l ../gif.tar

gif.tar = 13066240 bytes total

# find . -name "*.png" -print | tar -cf ../png.tar -T -
# ls -l ../png.tar

png.tar = 21596160 bytes total
</pre>

<p>Next, you'll need to download and install the <a href=
"http://sourceforge.net/projects/littleutils/"><i>littleutils</i></a>.
It's a pretty standard "./configure &amp;&amp; make &amp;&amp; make
install" routine. Once that's done, we can optimize the images:</p>

<pre>
# find . -name "*.jp*g" -exec opt-jpg {} \;
# find . -name "*.JP*G" -exec opt-jpg {} \;
# find . -name "*.gif" -exec opt-gif {} \;
# find . -name "*.png" -exec opt-png {} \;
</pre>

<p>After some lengthy period of time (PNG optimization is
particularly <b>slow</b>), the images will be fully optimized. If
the <tt>tar</tt> commands above are repeated, we get the following
results (over a 6-megabyte improvement!):</p>

<pre>
jpg.tar + jpeg.tar + JPG.tar = 41185280 bytes total  (a 7% savings!)
gif.tar = 12759040 bytes total  (a 2.5% savings)
png.tar = 18452480 bytes total  (a 15% savings!!)
</pre>

<p>Also, if you scroll through the results, you'll find that
several files are misnamed. In particular, there were a lot of GIF
images posing as PNG images. (Apparently a few people out there
think that "mv image.gif image.png" is an easy way to convert image
files. Not quite...) There were even a few Windows BMP images
posing as PNG images. &lt;<i>blegh</i>&gt; A complete list of these
files can be found here: <a href=
"misc/lindholm/badfile.txt">badfile.txt</a>. If these files are
properly renamed and optimized (or better yet, properly converted
and optimized), then further filespace savings can be achieved.</p>

<p class="editorial">[ Thanks for spotting those for us, Brian; they're all
fixed now. I take some small pleasure in noting that all the errors, with
the exception of one class, were from before I took over running LG. The
errors that came from me - mea culpa - resulted from the fact that
"convert" fails to actually change the image type if the original file has
a mismatched extension; that script is now also fixed, with the image types
forced to the correct ones. -- Ben ]

<p>While this example clearly shows that <i>littleutils</i> can
be used to achieve considerable filespace savings, there are two
major caveats:</p>

<p><b>[1]</b> The image optimization in <i>littleutils</i> is
<b>aggressive</b>, with <b>all</b> extraneous information being
thrown away. This includes comments, ancillary tags, colorspace
information, etc. You ought to run a few test cases before
optimizing your entire Photoshop collection.</p>

<p><b>[2]</b> The image optimization in <i>littleutils</i> does
not preserve interlacing. GIF and PNG images will always have
interlacing removed, and JPEG images may be converted to
progressive or non-progressive (depending on which is smaller). If
interlacing is particularly important to you, you'll need to skip
optimization or modify the scripts to keep the interlacing as you
want.</p>

<p>However, for most website purposes, the optimization scripts
found in <i>littleutils</i> work quite well. Merry optimizing!!</p>

<p>For further website optimization, you might also consider
using the <tt>repeats</tt> utility, also from
<i>littleutils</i>. This nifty script will find duplicate files in
any directory tree. If run in the Linux Gazette directory, the
following duplicate files are found: <a href=
"misc/lindholm/repeats.txt">repeats.txt</a>. To reduce website
filespace requirements even further, all but one of the duplicates
could be deleted, and the HTML references to the deleted duplicates
could be pointed to the remaining copy.</p>


</p>


<!-- *** BEGIN author bio *** -->
<P>&nbsp;
<P>
<!-- *** BEGIN bio *** -->
<hr>
<p>
<img align="left" alt="[BIO]" src="../gx/2002/note.png" class="bio">

<!-- 
If the author has sent his pic, save it to the right directory
and enable the line below.

<img align="left" alt="[BIO]" src="../gx/authors/pic.jpg" class="bio">

-->
</p>
<em>

<p>
Brian Lindholm is a Virginia Tech graduate and middle-aged mechanical engineer
who started programming in BASIC on a TRS-80 Model I (way back in 1980).  In
the late eighties, he moved to Pascal and C on an IBM PC-compatible.
</p>

<p>
Over the years, Brian became increasingly disgruntled with the instability
and expense of the various Microsoft operating systems.  In particular,
he<strong>hated</strong> not being in full control of his system.  MOST
fortunately for him, however, he had a college roommate who ran Linux (way
back in the Linux 0.9 and Slackware 1.0 days).  That introduction was all
he needed.
</p>

<p>
Over the years, he's slowly learned more and more, and now manages to keep his
Debian system running happy and stable (even through two major upgrades: 2.2 to
3.0, and 3.0 to 3.1).  [A point of note:  His Debian system has NEVER crashed
on its own.  EVER.  Only power failures, attempts to boot off the wrong
partition, and a particularly flaky IDE Zip drive ever managed to take it
down.]  He <strong>loves</strong> Vim and has found Perl amazingly useful at work.
</p>

<p>
In his non-Linux life, Brian helps design power generation equipment (big power
plant stuff) for a living, occasionally records live music for people, reads
too much science fiction, and gets out on the Appalachian Trail as often as he
can.
</p>

</em>
<br clear="all">
<!-- *** END bio *** -->

<!-- *** END author bio *** -->

<div id="articlefooter">

<p>
Copyright &copy; 2005, Brian Lindholm. Released under the <a
href="http://linuxgazette.net/copying.html">Open Publication license</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>

<p>
Published in Issue 119 of Linux Gazette, October 2005
</p>

</div>


<div id="previousnextbottom">
<A HREF="howell.html" >&lt;-- prev</A> | <A HREF="oregan.html" >next --&gt;</A>
</div>


</div>






<div id="navigation">

<a href="../index.html">Home</a>
<a href="../faq/index.html">FAQ</a>
<a href="../lg_index.html">Site Map</a>
<a href="../mirrors.html">Mirrors</a>
<a href="../mirrors.html">Translations</a>
<a href="../search.html">Search</a>
<a href="../archives.html">Archives</a>
<a href="../authors/index.html">Authors</a>
<a href="../contact.html">Contact Us</a>

</div>



<div id="breadcrumbs">

<a href="../index.html">Home</a> &gt; 
<a href="index.html">October 2005 (#119)</a> &gt; 
Article

</div>





<img src="../gx/tux_86x95_indexed.png" id="tux" alt="Tux"/>




</body>
</html>

