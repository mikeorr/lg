<!DOCTYPE html
	PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
	 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="utf-8" xml:lang="utf-8">
<head>
<title>
Linux Gazette : August 2010 (#177) 
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link href="../lg.css" rel="stylesheet" type="text/css" media="screen, projection" />

<style type="text/css" media="screen, projection">
<!--

.twdtarticle {
	width: 84%;
}

.twdtarticle h1 {
	font-size:19px;
	text-align:center;
}

.lgcontent {
        width: 84%;
        margin-top: 30px;
}

-->
</style>

</head>

<body id="twdtbody">

<a href="../">
<img src="../gx/2003/newlogo-blank-200-gold2.jpg" alt="Linux Gazette" id="twdtlogo"/>
</a>
<p id="fun">...making Linux just a little more fun!</p>

<div id="navigation">

<a href="../index.html">Home</a>
<a href="../faq/index.html">FAQ</a>
<a href="../lg_index.html">Site Map</a>
<a href="../mirrors.html">Mirrors</a>
<a href="../mirrors.html">Translations</a>
<a href="../search.html">Search</a>
<a href="../archives.html">Archives</a>
<a href="../authors/index.html">Authors</a>
<a href="http://lists.linuxgazette.net/listinfo.cgi">Mailing Lists</a>
<a href="../jobs.html">Join Us!</a>
<a href="../contact.html">Contact Us</a>
</div>

<div id="breadcrumbs1">

<a href="../index.html">Home</a> &gt;
<a href="index.html">August 2010 (#177)</a> &gt;
TWDT

</div>


<div class="content lgcontent">

<h2>August 2010 (#177):</h2>

<ul>

	<li><a href="#lg_mail">Mailbag</a>

	<li><a href="#lg_talkback">Talkback</a>

	<li><a href="#lg_tips">2-Cent Tips</a>

	<li><a href="#lg_bytes">News Bytes</a>, by <i>Deividson Luiz Okopnik and Howard Dyckoff</i></li>

	<li><a href="#borisov">A way to connect an iPod Touch to a MIPSnetbook</a>, by <i>Anton Borisov</i></li>

	<li><a href="#dyckoff">Away Mission: SemTech 2010 - Summary</a>, by <i>Howard Dyckoff</i></li>

	<li><a href="#grebler">Tunnel Tales 2</a>, by <i>Henry Grebler</i></li>

	<li><a href="#hoogland">Overview: Common Linux desktops</a>, by <i>Jeff Hoogland</i></li>

	<li><a href="#schneider">Installing Windows Server 2003 with Linux + PXE + DHCP + TFTP</a>, by <i>Will Schneider</i></li>

	<li><a href="#silva">Goodbye iPhone, Hello Palm Pre Plus</a>, by <i>Anderson Silva</i></li>

	<li><a href="#collinge">HelpDex</a>, by <i>Shane Collinge</i></li>

	<li><a href="#xkcd">XKCD</a>, by <i>Randall Munroe</i></li>

	<li><a href="#doomed">Doomed to Obscurity</a>, by <i>Pete Trbovich</i></li>

</ul>

</div>



<br />


<div class="content lgcontent">

<a name="lg_mail"></a>
<h1>Mailbag</h1>

</b>
</p>

<p>
<h3>This month's answers created by:</h3><strong>[  Anderson Silva, Steve 'Ashcrow' Milner, Amit Kumar Saha, Ben Okopnik, S. Parthasarathy, Henry Grebler, Kapil Hari Paranjape, Karl-Heinz Herrmann, Ren&eacute; Pfeiffer, Mulyadi Santosa, Neil Youngman, Paul Sephton, Kiniti Patrick, Aioanei Rares, Steve Brown  ]</strong>
<br />...and you, our readers!<br /><hr width="50%" align="center" size="3" /><h1>Our Mailbag</h1>
<hr />

<!-- Thread anchor: 'aptitude' Easter egg --><a name='aptitude_easter_egg'></a>
<h3>'aptitude' Easter egg</h3>
<p>
<b><p>
Ben Okopnik [ben at linuxgazette.net]
</p>

<p>

</p>
</b><br />
<b>Wed, 14 Jul 2010 11:41:39 -0400</b>
</p>

<p>
Run the following, one at a time:
</p>

<pre>
aptitude -v moo
aptitude -vv moo
aptitude -vvv moo
aptitude -vvvv moo
aptitude -vvvvv moo
aptitude -vvvvvv moo
</pre>

<p>
<img src="../gx/smile.png" alt=":)">
</p>

<pre>-- 
* Ben Okopnik * Editor-in-Chief, Linux Gazette * <a href='http://LinuxGazette.NET'>http://LinuxGazette.NET</a> *
</pre>

<p>

</p>

<p><b>[  <a name="mb-aptitude_easter_egg"></a> <a href="misc/lg/aptitude_easter_egg.html">Thread continues here (2 messages/1.58kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: TAG postings --><a name='tag_postings'></a>
<h3>TAG postings</h3>
<p>
<b><p>
Dr. Parthasarathy S [drpartha at gmail.com]
</p>

<p>

</p>
</b><br />
<b>Mon, 12 Jul 2010 10:43:06 +0530</b>
</p>

<p>
I have received quite a few comments and suggestions concerning my
"linusability" project. thank you all. I am trying to make a
consoldiated summary of all suggestions I have received. I seem to
have misplaced/lost some of the mails. I would like to retrieve them
from the TAG mailing list. Is  there an archive of TAG mails somewhere
? I tried but could get to only the archives of LG issues. Cat find
TAG mail, back issues though.
</p>

<p>
Can someone guide me please ?
</p>

<p>
partha
</p>

<p>
PS You can follow my progress in the "linusability" project, from :
<a href='http://www.profpartha.webs.com/linusability.htm'>http://www.profpartha.webs.com/linusability.htm</a>
</p>

<pre>-- 
---------------------------------------------------------------------------------------------
Dr. S. Parthasarathy                    |   mailto:drpartha at gmail.com
Algologic Research &amp; Solutions    |
78 Sancharpuri Colony                 |
Bowenpally  P.O                          |   Phone: + 91 - 40 - 2775 1650
Secunderabad 500 011 - INDIA     |
WWW-URL: <a href='http://algolog.tripod.com/nupartha.htm'>http://algolog.tripod.com/nupartha.htm</a>
---------------------------------------------------------------------------------------------
</pre>

<p>

</p>

<p><b>[  <a name="mb-tag_postings"></a> <a href="misc/lg/tag_postings.html">Thread continues here (4 messages/4.02kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: Face detection in Perl --><a name='face_detection_in_perl'></a>
<h3>Face detection in Perl</h3>
<p>
<b><p>
Jimmy O'Regan [joregan at gmail.com]
</p>

<p>

</p>
</b><br />
<b>Sat, 3 Jul 2010 22:24:59 +0100</b>
</p>

<p>
On 27 June 2010 18:46, Jimmy O'Regan &lt;joregan at gmail.com&gt; wrote:
</p>

<pre>
&gt; Since I got commit access to Tesseract, I've been getting a little
&gt; more interested in image recognition in general, and I was pleased to
&gt; find a Java-based 'face annotation' system on Sourceforge:
&gt; <a href='http://faint.sourceforge.net'>http://faint.sourceforge.net</a>
&gt;
</pre>

<p>
I just saw this headline on ReadWriteWeb: "Facebook Adds Facial
Recognition" (<a href='http://www.readwriteweb.com/archives/facebook_adds_facial_recognition.php'>http://www.readwriteweb.com/archives/facebook_adds_facial_recognition.php</a>).
Of course, being a blog aimed more at management types, they are, of
course, wrong. According to Facebook
(<a href='http://blog.facebook.com/blog.php?post=403838582130'>http://blog.facebook.com/blog.php?post=403838582130</a>) they've added
face <strong>detection</strong>...
</p>

<p>
They're probably either using OpenCV or the part of the Neven code
that Google added to Android
(<a href='http://android.git.kernel.org/?p=platform/external/neven.git;a=summary'>http://android.git.kernel.org/?p=platform/external/neven.git;a=summary</a>)
</p>

<pre>-- 
&lt;Leftmost&gt; jimregan, that's because deep inside you, you are evil.
&lt;Leftmost&gt; Also not-so-deep inside you.
</pre>

<p>

</p>

<hr />


<!-- Thread anchor: I'm utterly gobsmacked --><a name='i_m_utterly_gobsmacked'></a>
<h3>I'm utterly gobsmacked</h3>
<p>
<b><p>
Jimmy O'Regan [joregan at gmail.com]
</p>

<p>

</p>
</b><br />
<b>Sun, 25 Jul 2010 00:34:57 +0100</b>
</p>

<p>
This is, hands down, the single dumbest bug report I've ever seen:
<a href='http://code.google.com/p/tesseract-ocr/issues/detail?id=337'>http://code.google.com/p/tesseract-ocr/issues/detail?id=337</a>
</p>

<p>
I'm kind of reminded of the usability thread, because whenever I see a
dumb question on the Tesseract list, or in the issue tracker, it's
<strong>always</strong> a Windows user.
</p>

<p>
But mostly, I'm just wondering: can anybody think of a valid reason
why anyone would want to OCR a CAPTCHA?
</p>

<pre>-- 
&lt;Leftmost&gt; jimregan, that's because deep inside you, you are evil.
&lt;Leftmost&gt; Also not-so-deep inside you.
</pre>

<p>

</p>

<p><b>[  <a name="mb-i_m_utterly_gobsmacked"></a> <a href="misc/lg/i_m_utterly_gobsmacked.html">Thread continues here (9 messages/11.70kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: Mini-puter/bridge/etc. --><a name='mini_puter_bridge_etc'></a>
<h3>Mini-puter/bridge/etc.</h3>
<p>
<b><p>
Ben Okopnik [ben at linuxgazette.net]
</p>

<p>

</p>
</b><br />
<b>Thu, 1 Jul 2010 12:59:55 -0400</b>
</p>

<p>
Hi, all -
</p>

<p>
I've been trying to do some research on this topic, but am coming up dry
(or at least very sparse on good choices.) I'm hoping that someone here
will have an answer.
</p>

<p>
A few days ago, I got an AirPort Extreme - a wireless bridge + USB
gadget from Apple - so I could "unwire" my poor spiderwebbed laptop. Had
to set it up on a Windows machine [1], then started playing around with
the possibilities. Plugged in my new high-gain "client bridge" that's up
my mast (really, really impressive gadget, by the way
- <a href='http://islandtimepc.com/marine_wifi.html'>http://islandtimepc.com/marine_wifi.html</a>) - PoE connector snaps right
  into the WAN plug, AirPort hooks into it, life is good. Plugged in a
USB hub, hooked up my HP printer, told the AirPort software to share it
- OK, that's all fine too. Hooked up the external hard drive... um.
Well, OK, a few hours of struggling with Windows file sharing, and
Samba, and more file sharing, and... argh. My external HD is formatted
as ext3, so - no joy there, despite Macs running BSD these days. No way
am I going to reformat it. Also, plugging in an external CD-ROM was a
total fail: the AirPort doesn't recognize it, even when plugged in
directly without a hub. In addition, there's no HTTP interface on this
thing: you have to use their (Windows or Mac only) software to talk to
it.
</p>

<p>
So, the AirPort is going back to the store - but now, I'm stuck with a
dream. It would be really, <strong>really</strong> nice to just connect power and maybe
an external monitor to the laptop, and have the external drive, a
CD-ROM, the printer, and the network all available wirelessly. After
noodling on this for a bit, a small light went on. I said to myself:
"Self... what if you had a small beige box of some sort that was running
Linux and had all that stuff plugged into it?" At that point, none of
the above peripherals would present a problem: they'd just be available
<strong>stuff</strong>, accessible via standard protocols.
</p>

<p>
The only question is, what's the cheapest, smallest box that I can get?
Obviously, it needs to have at least one USB port, one Ethernet port,
and be accessible via WiFi. If it runs on 12 volts, that would be a
great plus. Recommendations on a flavor of Linux to run on this
gadget would also be welcome.
</p>

<p>
Thanks in advance for any suggestions!
</p>


<p>
[1] All FOSS-vs.-proprietary rhetoric aside... how the HELL do people
put up with Windows? I had to struggle through so many "YOUR MACHINE MAY
BE INFECTED!!! BUY OUR SOFTWARE ***NOW!!!***" warnings,
update-and-reboot repeats, instances of software automatically firing up
a browser and taking you to the company webpage, and completely
senseless procedures ("sharing" a network-accessible disk is a complete
lather-rinse-repeat nightmare) that I found myself literally screaming
"STOP already!" in frustration. And I'm not what you'd call
computer-illiterate, nor completely unfamiliar with Windows - although I
haven't used it in several years. That was just a horrible experience
that I hope I never have to repeat.
</p>

<pre>-- 
* Ben Okopnik * Editor-in-Chief, Linux Gazette * <a href='http://LinuxGazette.NET'>http://LinuxGazette.NET</a> *
</pre>

<p>

</p>

<p><b>[  <a name="mb-mini_puter_bridge_etc"></a> <a href="misc/lg/mini_puter_bridge_etc.html">Thread continues here (12 messages/21.75kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: linusability...again --><a name='linusability_again'></a>
<h3>linusability...again</h3>
<p>
<b><p>
Dr. Parthasarathy S [drpartha at gmail.com]
</p>

<p>

</p>
</b><br />
<b>Fri, 16 Jul 2010 13:14:31 +0530</b>
</p>

<p>
One frequent problem faced by Linux adherents like me is the
difficulty of finding hardware which is supported by Linux. Here is
some hope for us::
</p>

<p>
<a href='http://www.linuxpromagazine.com/Online/News/Open-Source-Hardware-Gets-Defined'>http://www.linuxpromagazine.com/Online/News/Open-Source-Hardware-Gets-Defined</a>
</p>

<p>
Take a look.
</p>

<p>
partha
</p>

<pre>-- 
---------------------------------------------------------------------------------------------
Dr. S. Parthasarathy                    |   mailto:drpartha at gmail.com
Algologic Research &amp; Solutions    |
78 Sancharpuri Colony                 |
Bowenpally  P.O                          |   Phone: + 91 - 40 - 2775 1650
Secunderabad 500 011 - INDIA     |
WWW-URL: <a href='http://algolog.tripod.com/nupartha.htm'>http://algolog.tripod.com/nupartha.htm</a>
---------------------------------------------------------------------------------------------
</pre>

<p>

</p>

<p><b>[  <a name="mb-linusability_again"></a> <a href="misc/lg/linusability_again.html">Thread continues here (2 messages/3.59kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: On the use of flash --><a name='on_the_use_of_flash'></a>
<h3>On the use of flash</h3>
<p>
<b><p>
Ben Okopnik [ben at linuxgazette.net]
</p>

<p>

</p>
</b><br />
<b>Tue, 13 Jul 2010 15:42:15 -0400</b>
</p>

<p>
----- Forwarded message from "Mikko V. Viinam?ki" &lt;Mikko.Viinamaki at students.turkuamk.fi&gt; -----
</p>

<pre>
Date: Sat, 10 Jul 2010 20:35:36 +0300
From: "Mikko V. Viinam?ki" &lt;Mikko.Viinamaki@students.turkuamk.fi&gt;
To: TAG &lt;tag@lists.linuxgazette.net&gt;
To: "editor at linuxgazette.net" &lt;editor at linuxgazette.net&gt;
Subject: On the use of flash
</pre>
I just wanted to object. No cartoon is way better than a flash cartoon.
</p>

<p>
I see you've hashed it somewhat already. Just my 2 cents.
</p>

<p>
I really like the gazette otherwise.
</p>

<p>
Mikko
</p>

<p>
----- End forwarded message -----
</p>

<pre>-- 
* Ben Okopnik * Editor-in-Chief, Linux Gazette * <a href='http://LinuxGazette.NET'>http://LinuxGazette.NET</a> *
</pre>

<p>

</p>

<p><b>[  <a name="mb-on_the_use_of_flash"></a> <a href="misc/lg/on_the_use_of_flash.html">Thread continues here (7 messages/11.63kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: JPEG de-duplication --><a name='jpeg_de_duplication'></a>
<h3>JPEG de-duplication</h3>
<p>
<b><p>
Neil Youngman [ny at youngman.org.uk]
</p>

<p>

</p>
</b><br />
<b>Sun, 25 Jul 2010 21:19:34 +0100</b>
</p>

<p>
A family member has a number of directories containing photos in JPEG format. 
3 directories contain different versions of the same collection of photos. 
One is the current master and the others are earlier snapshots of the same 
collection. I believe that all the photos in the older snapshots are present 
in the current master, but I would like to verify that before I delete them. 
Also many other directories probably contain duplicates of photos in the 
master collection and I would like to clean those up.
</p>

<p>
Identifying and cleaning up byte for byte identical JPEGs in the snapshots has 
freed up a considerable amount of disk space. A sample of the remaining 
photos suggests that they are probably in the master, but the tags and 
position in the directory tree have changed. I don't want to go through 
comparing them all by hand. 
</p>

<p>
Initial research suggests that ImageMagick can produce a "signature", which is 
a SHA256 checksum of the image data. I believe that this would be suitable 
for identifying identical images, on which the tags have been altered. 
</p>

<p>
Are there any graphics experts in the gang who can confirm this? Alternatively 
suggestions of existing tools that will do the job, or better approaches, 
would be most welcome.
</p>

<p>
Neil
</p>

<p>

</p>

<p><b>[  <a name="mb-jpeg_de_duplication"></a> <a href="misc/lg/jpeg_de_duplication.html">Thread continues here (26 messages/33.37kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: Photo recovery from a formatted flash memory card --><a name='photo_recovery_from_a_formatted_flash_memory_card'></a>
<h3>Photo recovery from a formatted flash memory card</h3>
<p>
<b><p>
Neil Youngman [ny at youngman.org.uk]
</p>

<p>

</p>
</b><br />
<b>Mon, 5 Jul 2010 08:02:06 +0100</b>
</p>

<p>
Recently I've needed to recover photos from 2 compact flash cards, one of 
which was accidentally formatted and one of which was faulty. Subsequently I 
have used the "expertise" acquired to recover photos from a formatted SD card 
as a favour to a random stranger on the internet.
</p>

<p>
The first thing I did was backup the card, using a simple dd if=/dev/sdX1 
of=/path/to/data
</p>

<p>
The first time I did this, I was in a hurry. I had seen a lot of 
recommendations for a Windows tool called Recuva and I didn't want to spend 
much time on research, so I just grabbed a copy of that. It seemed to work 
just fine "recovering" 1045 files, but on closer inspection, none of them 
were complete. They should have been 3-5 MB jpegs, but they were all about 
1.5MB and only the thumbnails were viewable. I messed about with the 
settings, to no effect and looked at a couple of other Windows tools, before 
I saw a recommendation for photorec, which is part of Christophe Grenier's 
testdisk suite. <a href='http://www.cgsecurity.org/wiki/PhotoRec'>http://www.cgsecurity.org/wiki/PhotoRec</a>
</p>

<p>
Photorec looked like a Unix native tool, so I downloaded the appropriate 
tarball, unpacked it and ran it. It took the file name of my backup as an 
argument, so I didn't even need to have the card handy. I walked  through a 
few simple menu options and it recovered just over 1000 photos. This time 
they all appeared to complete, full resolution photos. As far as I could tell 
there was nothing missing.
</p>

<p>
Reading through the instructions, I found that there was probably junk data at 
the end of the photos, which could be removed by running convert (from the 
ImageMagick suite) on the jpeg.
</p>

<p>
The sequence of commands below is how I recovered the photos from the SD card.
</p>

<p>
<pre class='code'>
$ dd if=/dev/sdd1 of=/tmp/sdcard.bin
$  ~/testdisk-6.11.3/linux/photorec_static /tmp/sdcard.bin 
$ mkdir /tmp/recovered
$ for file in /tmp/recup_dir.1/*.jpg; do 
convert "$file" "/tmp/recovered/$(basename $file)"; done
</pre>

<p>
The first command is just a binary copy of the raw data from the SD card to a 
file.
</p>

<p>
The next command obviously runs photorec itself. In the menus, just accepting 
the defaults is usually sufficient, but you have to select a directory in 
which to store the results. Photorec actually creates subdirectories under 
that directory, called recup_dir.N. In this case I selected /tmp/ to store 
the recovered photos in.
</p>

<p>
Having recovered the photos, I created the directory /tmp/recovered and ran a 
loop, calling convert on the files, as explained above. That directory, 
containing the final results was then burned to a CD, which was sent to the 
owner of the photos. 
</p>

<p>
As you can see photorec is a very simple tool to use and as far as I could, it 
recovered all the files that we expected to find on the various flash cards. 
I would recommend it to anyone who has a need to recover photos from a 
corrupt, defective or formatted flash card.
</p>

<p>
Neil Youngman
</p>

<p>

</p>

<p><b>[  <a name="mb-photo_recovery_from_a_formatted_flash_memory_card"></a> <a href="misc/lg/photo_recovery_from_a_formatted_flash_memory_card.html">Thread continues here (2 messages/3.82kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: Working with External Sensors --><a name='working_with_external_sensors'></a>
<h3>Working with External Sensors</h3>
<p>
<b><p>
Deividson Okopnik [deivid.okop at gmail.com]
</p>

<p>

</p>
</b><br />
<b>Mon, 12 Jul 2010 13:48:36 -0300</b>
</p>

<p>
Hello TAG!
</p>

<p>
Im doing some research in here, and was wondering if any of you ever
worked with external sensors.
</p>

<p>
What i had in mind was having temp/humidity sensors plugged into my
computer and reading theyr values on linux to use on some program ill
write.
</p>

<p>
If anyone ever did this, what kind of hardware did you use?
</p>

<p>

</p>

<p><b>[  <a name="mb-working_with_external_sensors"></a> <a href="misc/lg/working_with_external_sensors.html">Thread continues here (5 messages/8.48kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: Linusability --><a name='linusability'></a>
<h3>Linusability</h3>
<p>
<b><p>
Dr. Parthasarathy S [drpartha at gmail.com]
</p>

<p>

</p>
</b><br />
<b>Thu, 8 Jul 2010 09:03:17 +0530</b>
</p>

<p>
Linux usability -- an introspection (Code name ::  linusability)
</p>

<p>
In spite of all claims and evidence regarding the superiority of
Linux, one aspect of Linux remains to be its major weakness --
usability. This may be the reason for its slow acceptance by the
not-so-geeky user community. I am launhing a serious study into
various aspects of the usability aspects of Linux, so as to list
out the problems and hopefully help some people offer solutions.
</p>

<p>
I need help. Please, if you have any ideas on this subject, or if
you know any sources where I can get directions, or if there is
something I should (or should not) do, let me know directly, by
email. I will compile all my findings, and post them back in this
forum. Let us make Linux more enjoyable by more people.
</p>

<p>
Many thanks,
</p>

<p>
partha AT gmail DOT com
</p>


<pre>-- 
---------------------------------------------------------------------------------------------
Dr. S. Parthasarathy                    |   mailto:drpartha at gmail.com
Algologic Research &amp; Solutions    |
78 Sancharpuri Colony                 |
Bowenpally  P.O                          |   Phone: + 91 - 40 - 2775 1650
Secunderabad 500 011 - INDIA     |
WWW-URL: <a href='http://algolog.tripod.com/nupartha.htm'>http://algolog.tripod.com/nupartha.htm</a>
---------------------------------------------------------------------------------------------
</pre>

<p>

</p>

<p><b>[  <a name="mb-linusability"></a> <a href="misc/lg/linusability.html">Thread continues here (19 messages/62.99kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: Kernel Panic Not Syncing VFS --><a name='kernel_panic_not_syncing_vfs'></a>
<h3>Kernel Panic Not Syncing VFS</h3>
<p>
<b><p>
Kiniti Patrick [pkiniti at techmaxkenya.com]
</p>

<p>

</p>
</b><br />
<b>Thu, 8 Jul 2010 12:42:08 +0300</b>
</p>

<p>
Hi Tag, 
</p>

<p>
I am currently running Fedora 11 on my Laptop and have run into some problem. My Laptop has been spewing random errors on boot up, displaying the following 
"crc error kernel panic - not Syncing VFS unable to mount root fs on unknown block (0,0). 
The boot process fails at this point. 
Following this, i tried to boot the Laptop using a Linux Dvd and run into the following roadblock. The error message displayed is " RAMDISK:  incomplete write  (13513 != 32768) write error 
Kernel Panic - not Syncing: VFS : unable to mount root fs on unknown block (0, 0). 
Has anyone experienced a similar problem. Kindly assist on how i can recover from the error. Thanks in advance. 
</p>

<p>
Regards,    
</p>

<p>
Kiniti Patrick
</p>

<p>

</p>

<p><b>[  <a name="mb-kernel_panic_not_syncing_vfs"></a> <a href="misc/lg/kernel_panic_not_syncing_vfs.html">Thread continues here (8 messages/12.66kB)</a>  ]</b></p>
<hr />


</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:177/lg_mail.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Published in Issue 177 of Linux Gazette, August 2010
</p>

</div>
</div>


<div class="content lgcontent">

<a name="lg_talkback"></a>
<h1>Talkback</h1>

</b>
</p>

<p>

<!-- Thread anchor: Talkback for LG article on QQ --><a name='talkback_for_lg_article_on_qq'></a>
<h3>Talkback for LG article on QQ</h3>
<p>
<b><p>
Ben Okopnik [ben at linuxgazette.net]
</p>

<p>

</p>
</b><br />
<b>Mon, 19 Jul 2010 23:09:54 -0400</b>
</p>

<p>
Hi, Silas -
</p>

<p>
On Mon, Jul 12, 2010 at 03:41:55PM +0100, Silas S. Brown wrote:
</p>

<pre>
&gt; (This message contains Chinese characters
&gt; in the UTF-8 encoding.)
</pre>

<p>
That <em>should</em> show up fine in LG; all our HTML has 'UTF-8' specified as
the encoding.
 
</p>

<pre>
&gt; I'd like to add two comment to my article
&gt; about using the Chinese instant messaging
&gt; service "QQ" on Linux, at
&gt; <a href='../167/brownss.html'>http://linuxgazette.net/167/brownss.html</a>
</pre>

<p>
Just FYI - we generally avoid changing articles after publication. Given
that we have quite a few mirror sites, all of which pull our new issues
shortly after publication (and then never touch them again), changing
our copy would just put us out of sync with the rest of the world.
</p>

<p>
The best way to "update" an article is either by writing a new one about
the updated state of things - or do what you've done here, i.e. post to
TAG.
</p>


<pre>
 祝
一切顺利!
</pre>
<pre>-- 
* Ben Okopnik * Editor-in-Chief, Linux Gazette * <a href='http://LinuxGazette.NET'>http://LinuxGazette.NET</a> *
</pre>

<p>

</p>

<p><b>[  <a name="mb-talkback_for_lg_article_on_qq"></a> <a href="misc/lg/talkback_for_lg_article_on_qq.html">Thread continues here (5 messages/3.92kB)</a>  ]</b></p>
<hr />


<br clear="all" />

<table align='center' cellspacing='10'>
<tr>
<td>
<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/177/lg_talkback.html';
digg_title = 'Talkback';
digg_bodytext = '<p>In this month\'s Linux Gazette, \'Talkback\' covers the following topics:<br>Talkback for LG article on QQ<br></p>';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>
</td>
<td>
<a name="fb_share" type="box_count" href="http://www.facebook.com/sharer.php">Share</a>
<script src="http://static.ak.fbcdn.net/connect.php/js/FB.Share" type="text/javascript"></script>
</td>
<td>
<a href="http://twitter.com/home?status=Currently%20reading:%20http://linuxgazette.net/177/lg_talkback.html%20at%20Linux%20Gazette%20%23linuxgazette" title="Click to share this post on Twitter"><img src="../gx/twitter.png" width="50" height="85" border="0"></a>
</td>
</tr>
</table>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:177/lg_talkback.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Published in Issue 177 of Linux Gazette, August 2010
</p>

</div>
</div>


<div class="content lgcontent">

<a name="lg_tips"></a>
<h1>2-Cent Tips</h1>

</b>
</p>

<p>

<!-- Thread anchor: 2-cent Tips: understand file system hierarchy right from the man pages --><a name='2_cent_tips__understand_file_system_hierarchy_right_from_the_man_pages'></a>
<h3>2-cent Tips: understand file system hierarchy right from the man pages</h3>
<p>
<b><p>
Mulyadi Santosa [mulyadi.santosa at gmail.com]
</p>

<p>

</p>
</b><br />
<b>Fri, 23 Jul 2010 14:28:18 +0700</b>
</p>

<p>
Probably one of my shortest tips so far:
</p>

<p>
Confused with all those /proc, /sys, /dev, /boot etc really mean and
why on Earth they are there? Simply type "man hier" in your shell and
hopefully you'll understand <img src="../gx/smile.png" alt=":)">
</p>

<p>
-- 
regards,
</p>

<p>
Mulyadi Santosa
Freelance Linux trainer and consultant
</p>

<p>
blog: the-hydra.blogspot.com
training: mulyaditraining.blogspot.com
</p>

<p>

</p>

<p><b>[  <a name="mb-2_cent_tips__understand_file_system_hierarchy_right_from_the_man_pages"></a> <a href="misc/lg/2_cent_tips__understand_file_system_hierarchy_right_from_the_man_pages.html">Thread continues here (4 messages/3.80kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: 2-cent tip: De-Microsofting text files --><a name='2_cent_tip__de_microsofting_text_files'></a>
<h3>2-cent tip: De-Microsofting text files</h3>
<p>
<b><p>
Ben Okopnik [ben at linuxgazette.net]
</p>

<p>

</p>
</b><br />
<b>Fri, 23 Jul 2010 14:21:02 -0400</b>
</p>

<p>
I was doing some PDF to HTML conversions today, and noticed some really
ugly, borken content in the resulting files; the content had obviously
been created via some Microsoft program (probably Word):
</p>

<p>
Just say ?&lt;80&gt;&lt;98&gt;hello, world!?&lt;80&gt;&lt;99&gt;?&lt;80&gt;&lt;9d&gt; 
</p>

<p>
I had a few dozen docs to fix, and didn't have a mapping of the
characters with which I wanted to replace these ugly clumps of hex. That
is, I could <em>see</em> what I wanted, but expressing it in code would take a
bit more than that.
</p>

<p>
Then, I got hit by an idea. After I got up, rubbed the bruise, and took
an aspirin, I wrote the following:
</p>

<p>
<pre class='code'>
#!/usr/bin/perl -w
# Created by Ben Okopnik on Fri Jul 23 12:05:05 EDT 2010
use encoding qw/utf-8/;
 
my ($s, %seen) = do { local $/; &lt;&gt; };
# Delete all "normal" characters
$s =~ s/[\011\012\015\040-\176]//g;
print "#!/usr/bin/perl -i~ -wp\n\n";
for (split //, $s){ next if $seen{$_}++; print "s/$_//g;\n"; }
</pre>

<p>
When this script is given a list of all the text files as arguments, it
collects a unique list of the UTF-8 versions of all the "weird"
characters and outputs a <strong>second</strong> Perl script which you can now edit to
define the replacements:
</p>

<p>
<pre class='code'>
#!/usr/bin/perl -i~ -wp
 
s/\xFE\xFF//g;
s/?//g;
s/?//g;
s/?//g;
s/?//g;
s/?//g;
s/?//g;
s/?//g;
s/?//g;
</pre>

<p>
Note that the second half of each substitution is empty; that's where
you put in your replacements, like so:
</p>

<p>
<pre class='code'>
#!/usr/bin/perl -i~ -wp
 
s/\xFE\xFF//g;	# We'll get rid of the 'BOM' marker
s/?/"/g;
s/?/-/g;
s/?/'/g;
s/?/"/g;
s/?/-/g;
s/?/.../g;
s/?/'/g;
s/?/&amp;copy;/g;	# We'll make an HTML entity out of this one
</pre>

<p>
Now, just make this script executable, feed it a list of all your text
files, and live happily ever after. Note that the original versions will
be preserved with a '~' appended to their filenames, just in case.
</p>


<pre>-- 
* Ben Okopnik * Editor-in-Chief, Linux Gazette * <a href='http://LinuxGazette.NET'>http://LinuxGazette.NET</a> *
</pre>

<p>

</p>

<p><b>[  <a name="mb-2_cent_tip__de_microsofting_text_files"></a> <a href="misc/lg/2_cent_tip__de_microsofting_text_files.html">Thread continues here (5 messages/7.54kB)</a>  ]</b></p>
<hr />


<br clear="all" />

<table align='center' cellspacing='10'>
<tr>
<td>
<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/177/lg_tips.html';
digg_title = '2-Cent Tips';
digg_bodytext = '<p>In this month\'s Linux Gazette, \'2-Cent Tips\' covers the following topics:<br>2-cent Tips: understand file system hierarchy right from the man pages<br>2-cent tip: De-Microsofting text files<br></p>';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>
</td>
<td>
<a name="fb_share" type="box_count" href="http://www.facebook.com/sharer.php">Share</a>
<script src="http://static.ak.fbcdn.net/connect.php/js/FB.Share" type="text/javascript"></script>
</td>
<td>
<a href="http://twitter.com/home?status=Currently%20reading:%20http://linuxgazette.net/177/lg_tips.html%20at%20Linux%20Gazette%20%23linuxgazette" title="Click to share this post on Twitter"><img src="../gx/twitter.png" width="50" height="85" border="0"></a>
</td>
</tr>
</table>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:177/lg_tips.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Published in Issue 177 of Linux Gazette, August 2010
</p>

</div>
</div>


<div class="content lgcontent">

<a name="lg_bytes"></a>
<h1>News Bytes</h1>
<p id="by"><b>By <a href="../authors/dokopnik.html">Deividson Luiz Okopnik</a> and <a href="../authors/dyckoff.html">Howard Dyckoff</a></b></p>

</b>
</p>

<p>
<style type="text/css">
<!--
#news h2 { color: green; text-align: center; }
#news h3 { color: green; }
-->
</style>


<p>
<center>
<table cellpadding="7">
<tr>
<td>
<img src="../gx/bytes.gif" border="1" alt="News Bytes">
</td>
<td>
<h3>Contents:</h3>
<ul>
<li><a href="#general">News in General</a>
<li><a href="#Events">Conferences and Events</a>
<li><a href="#distro">Distro News</a>
</li><li><a href="#commercial">Software and Product News</a>
</ul>
</td>
</tr>
</table>
<strong>Selected and Edited by <a href="mailto:bytes@linuxgazette.net">Deividson Okopnik</a></strong>
</center>

<p style="font-style: italic"> Please submit your News Bytes items in
<strong>plain text</strong>; other formats may be rejected without reading.
[You have been warned!]  A one- or two-paragraph summary plus a URL has a
much higher chance of being published than an entire press release. Submit
items to <a
href="mailto:bytes@linuxgazette.net">bytes@linuxgazette.net</a>. Deividson can also be reached via <a href="http://www.twitter.com/deivid_okop">twitter</a>.</p>

<hr>

<div id="news">

<p>
<a name="general"></a>
<h2>News in General</h2>
<h3><img alt="lightning bolt" src="../gx/bolt.gif">Rackspace and NASA Open Source Cloud Platform</h3>

<p>In July, Rackspace Hosting announced the launch of OpenStack, an 
open-source cloud platform designed to foster the emergence of 
technology standards and cloud interoperability. Rackspace is donating 
the code that powers its Cloud Files and Cloud Servers public-cloud 
offerings to the OpenStack project. </p>

<p>The project will also incorporate technology that powers the NASA 
Nebula Cloud Platform. </p>
<p>Rackspace and NASA plan to actively collaborate on joint technology 
development and leverage the efforts of open-source software 
developers worldwide.</p>

<p>"We are founding the OpenStack initiative to help drive industry 
standards, prevent vendor lock-in and generally increase the velocity 
of innovation in cloud technologies," said Lew Moorman, President, 
Cloud and CSO at Rackspace. "We are proud to have NASA's support in 
this effort.  Its Nebula Cloud Platform is a tremendous boost to the 
OpenStack community. We expect ongoing collaboration with NASA and the 
rest of the community to drive more-rapid cloud adoption and 
innovation, in the private and public spheres."</p>

<p>A fully distributed object store based on Rackspace Cloud Files is now 
at OpenStack.org.  The next component planned for release is a 
scalable compute-provisioning engine based on the NASA Nebula cloud 
technology and Rackspace Cloud Servers technology. It is expected to 
be available later this year.  Using these components, organizations 
would be able to turn physical hardware into scalable and extensible 
cloud environments using the same code currently in production serving 
tens of thousands of customers and large government projects.</p>


<h3><img alt="lightning bolt" src="../gx/bolt.gif">Marvell Open-sources Easy Plug Computer Installer</h3>

<p>Marvell announced the availability of the open source Easy 
Plug-Computer Installer (EPI) to simplify Plug Computing software 
deployment. EPI is a wizard-based installation tool for Marvell's Plug 
Computer design, providing Plug Computer developers with a faster way 
to build their low-power Plug Computing solutions.  Plug Computers are 
headless servers with open source HW and SW specifications.  Some of 
the common parts are used in mobile phones and run at very low power.</p>

<p>The award-winning Plug Computer design makes always on, green 
computing readily available for developers and end-users. Plug 
Computers feature a 2 GHz Marvell ARMADA 300 processor, and optional 
built-in hard-disk drive and embedded Marvell Wi-Fi and Bluetooth 
technologies. The enclosure can be just a few cubic inches with an 
ethernet port and a USB port.  Additional peripherals such as Direct 
Attached Storage (DAS) can be connected using the USB 2.0 port. 
Multiple standard Linux 2.6 kernel distributions are supported on the 
Plug Computer development platform. The enclosure plugs directly into 
a standard wall socket and draws less than one tenth of the power of a 
typical PC being used as a home server. For more information, please 
visit <a href="http://www.plugcomputer.org">http://www.plugcomputer.org</a>.</p>

<p>Bob Salem, director of marketing at Marvell, told Linux Gazette that 
"... its a bit tedious to reprogram the plug. Our new EP installer 
makes this simpler and faster.  There is no jtag, no set up. EPI 
allows our partners to remotely upgrade their hardware in the field."</p>

<p>"Marvell wants to encourage more developers to explore Plug Computing 
and the high performance, eco-friendly open source computing 
platform,"said Viren Shah, Senior Director of Marketing Embedded 
Systems at Marvell's Enterprise Business Unit.</p>

<p>Examples of Plug Computers currently available for purchase at $89-$99 
are Cloud Engines' PogoPlug, Axentra's HipServ for PlugTop Computing, 
and the TonidoPlug low-power, personal server and NAS device which 
uses embedded Ubuntu 9.04 Linux.</p>

<p>EPI can be used to install Linux distributions, file systems, file 
system images or single applications. The application provides USB key 
and HTTP-based list retrieval, further expanding the ways in which 
developers can access and update Plug Computers. Developers also will 
have access to step-by-step instructions for successful deployment, 
along with access to new developments put forth by the Plug Computing 
community. The EPI is compatible with Fedora 11, Ubuntu 9.04, Windows 
XP SP2/3, and Mac OSX (Leopard).</p>

<p>The Easy Plug-Computer Installer and Marvell Plug Computers were on 
display at the OSCON 2010 tradeshow in Portland, Oregon in July.  EPI 
and supporting information is currently available for download at 
<a href="http://sourceforge.net/projects/esia/">http://sourceforge.net/projects/esia/</a>.</p>

<p>Marvell will host first meeting  of the new devleoper community at the 
Plugin Developer Day at their Santa Clara headquarters on Aug 18. </p>


<h3><img alt="lightning bolt" src="../gx/bolt.gif">MeeGo Platform Chosen by the GENIVI Alliance</h3>
<p>The Linux Foundation announced that GENIVI, an auto-alliance driving 
the adoption of In-Vehicle Infotainment (IVI), will adopt MeeGo as the 
standard for IVI in vehicles manufactured by car companies like BMW 
and General Motors. It had voiced support for MeeGo before but is now 
officially using it for its next IVI reference release (called 
Apollo). </p>

<p>MeeGo is an open source platform hosted by the Linux Foundation that 
brings together Intel and Nokia's previous mobile projects for 
computing devices such as smartphones, netbooks, tablets, mediaphones, 
connected TVs and IVI systems. MeeGo's platform contains a Linux base, 
middleware, and an interface layer that powers these rich 
applications.</p>

<p>IVI is a rapidly evolving field that encompasses the digital 
applications that can be used by all occupants of a vehicle, including 
navigation, entertainment, location-based services, and connectivity 
to devices, car networks and broadband networks. MeeGo will provide 
the base for the upcoming GENIVI Apollo release that will be used by 
members to reduce time to market and the cost of IVI development.</p>

<p>"We selected MeeGo as the open source basis for our platform because 
it is technically innovative and can provide the cross architecture 
build support we require for our references," said Graham Smethurst, 
President of GENIVI. "Working with MeeGo we expect to establish a 
solution that effectively merges IVI needs with those of the other 
MeeGo target device categories."</p>

<p>GENIVI is a nonprofit industry alliance with founding members BMW 
Group, Wind River, Intel, GM, PSA, Delphi, Magneti-Marelli, and 
Visteon.</p>

<p>An initial release of the MeeGo platform is available now from 
<a href="http://www.meego.com/downloads">http://www.meego.com/downloads</a>. The MeeGo project encourages all 
automakers or industry groups to participate in the MeeGo project or 
make use of its software to power their own distributions.</p>


<h3><img alt="lightning bolt" src="../gx/bolt.gif">OpenDocument 1.2 available for review for 60 days</h3>

<p>The complete draft of version 1.2 of the OpenDocument (ODF) standard 
was made publicly available in early July. Developers, potential users 
and others are invited to submit their comments on the draft before 
the 6th of September. Before the end of the fourth quarter of 2010, 
the members of the OASIS working group lead by Rob Weir, followed by 
the entire OASIS (Organisation for the Advancement of Structured 
Information Standards) membership, will vote then on whether to adopt 
the draft as an official OASIS standard.</p>

<p>If approved, the standard will then be presented to the ISO 
(International Standardisation Organisation) to be ratified as the 
current version of the ISO 26300 standard. OASIS is in charge of 
maintaining this standard, which will  promote the exchange of 
documents between different office suites.</p>

<p>Version 1.2 of the ODF has been particularly improved in terms of 
mathematical formulae.  According to a blog post by Rob Weir, the use 
of OpenFormula is not just designed to be used as a part of ODF, but 
also as a stand-alone syntax for other applications such as a separate 
equation parser.</p>

<p>Microsoft in particular had repeatedly criticised the previously only 
rudimentary definition of mathematical formulae in ODF spreadsheets as 
an interoperability flaw of the OpenDocument standard. The competing 
OOXML standard, driven by MS, describes every mathematical function 
that may appear as part of a formula in an Excel spreadsheet cell in 
great detail - which is one of the reasons why the Microsoft standard 
in turn has been heavily criticised for its more than 6,000 printed 
pages. The ODF 1.2 specification including OpenFormula comprises 1,100 
pages.</p>
<hr>

<a name="links"></a>
<h2>Conferences and Events</h2>
<p>
<dl> <dt> <strong>DebConf 10</strong> <dd>
August 1-7, New York, New York<br />
<a href="http://debconf10.debconf.org/">http://debconf10.debconf.org/</a>.</dl>

<dl> <dt> <strong>First Splunk Worldwide Users' Conference</strong> <dd>
August 9-11, 2010, San Francisco, CA<br />
<a href="http://www.splunk.com/goto/conference">http://www.splunk.com/goto/conference</a>.</dl>

<dl><dt><strong>LinuxCon 2010</strong><dd>
 August 10-12, Boston<br />

 <p> LinuxCon is the industry's premiere Linux conference that provides an
unmatched collaboration and education space for all matters Linux.
LinuxCon brings together the best and brightest that the Linux
community has to  offer,including core developers, administrators, end
users, business executives and operations experts - the best technical
talent and the decision makers and industry experts who are involved
in the Linux community.  Registration and information:
http://events.linuxfoundation.org/events/linuxcon </p>

 <p>Please register at the link below using this 20% discount code: LCB_LG10<br>
<a href="http://events.linuxfoundation.org/component/registrationpro/?func=details&amp;did=27">http://events.linuxfoundation.org/component/registrationpro/?func=details&amp;did=27</a>
</p>

<a href="http://events.linuxfoundation.org/events/linuxcon">
<img src="http://events.linuxfoundation.org/images/stories/headers/linuxcon2010_header.jpg"
border="0" width="450" height="70">
</a>
</dl>


<dl><dt><strong>19th USENIX Security Symposium (USENIX SEC '10)</strong><dd>
August 11–13 Washington DC<br />

<p>
Join us at the 19th USENIX Security Symposium, August 11–13, 2010, in
Washington, D.C.
</p>

<p>
Whether you're a researcher, a system administrator, or a policy wonk,
come to USENIX Security '10 to find out how changes in computer
security are going to affect you. The 3-day program includes an
innovative technical program, starting with a keynote address by Roger
G. Johnston of the Vulnerability Assessment Team at Argonne National
Laboratory; invited talks, including "Toward an Open and Secure
Platform for Using the Web," by Will Drewry, Google; a refereed papers
track, including 30 papers presenting the newest advances; and a
Poster session displaying the latest preliminary research. Gain
valuable knowledge on a variety of subject areas, including detection
of network attacks, privacy, Internet security, Web security, and
more.
</p>

<a href="http://www.usenix.org/sec10/lg">

<img src="http://www.usenix.org/events/sec10/art/sec10_banner_450.jpg" border="0" width="450" height="70" alt="SEC '10">
<br>http://www.usenix.org/sec10/lg</a></dl>


<dl> <dt> <strong>Plug In! Developer Camp</strong> <dd>
August 18th, Marvell campus, Santa Clara, CA<br />
<a href="http://www.marvell.com/company/events/">http://www.marvell.com/company/events/</a>.</dl>

<dl> <dt> <strong>PHPSC Conf 2010</strong> <dd>
August 27-28, Joinvile, Santa Catarina, Brazil<br />
<a href="http://www.phpsc.com.br/"><img src="http://www.phpsc.com.br/wp-content/uploads/2010/06/phpsc-619x111_exp.png" /></a>.</dl>

<dl> <dt> <strong>VM World 2010</strong> <dd>
August 30 - September 2, San Francisco, CA<br />
<a href="http://www.vmworld.com/index.jspa">http://www.vmworld.com/index.jspa</a>.</dl>

<dl> <dt> <strong>LinuxCon Brazil</strong> <dd>
August 31 - September 1, 2010, S&atilde;o Paulo, Brazil<br />
<a href="http://events.linuxfoundation.org/events/linuxcon-brazil">http://events.linuxfoundation.org/events/linuxcon-brazil</a>.</dl>

<dl> <dt> <strong>OOoCon 2010</strong> <dd>
August 31 - September 3, Budapest, Hungary<br />
<a href="http://www.ooocon.org/index.php/ooocon/2010">http://www.ooocon.org/index.php/ooocon/2010</a>.</dl>

<dl> <dt> <strong>Ohio Linuxfest 2010</strong> <dd>
September 10-12, Ohio<br />
<a href="http://www.ohiolinux.org/">http://www.ohiolinux.org/</a>.</dl>

<dl> <dt> <strong>Intel Developer Forum - IDF 2010</strong> <dd>
September 13-15, Moscone Center, San Francisco, CA<br />
<a href="http://www.intel.com/idf/">http://www.intel.com/idf/</a>.</dl>

<dl> <dt> <strong>Oracle Openworld 2010</strong> <dd>
September 19-23, San Francisco, CA<br />
<a href="http://www.oracle.com/us/openworld/">http://www.oracle.com/us/openworld/</a>.</dl>

<dl> <dt> <strong>Brocade Conference 2010</strong> <dd>
September 20-22, Mandalay Bay, Las Vegas, NV<br />
<a href="http://www.brocade.com/conference2010">http://www.brocade.com/conference2010</a>.</dl>

<dl> <dt> <strong>StarWest 2010</strong> <dd>
September 26 - October 1st, San Diego, CA<br />
<a href="http://www.sqe.com/starwest/">http://www.sqe.com/starwest/</a>.</dl>

<dl> <dt> <strong>LinuxCon Japan 2010</strong> <dd>
September 27-29, Roppongi Academy, Tokyo, Japan<br />
<a href="http://events.linuxfoundation.org/events/linuxcon-japan/">http://events.linuxfoundation.org/events/linuxcon-japan/</a>.</dl>

<dl> <dt> <strong>Mobilize! 2010</strong> <dd>
September 30, Mission Bay Center, San Francisco, CA<br />
<a href="http://events.gigaom.com/mobilize/10/">http://events.gigaom.com/mobilize/10/</a>.</dl>

<dl> <dt> <strong>17th Annual Tcl/Tk Conference (Tcl'2010)</strong> <dd>
October 11-15, Hilton Suites, Oakbrook Terrace, Ill<br />
<a href="http://www.tcl.tk/community/tcl2010/">http://www.tcl.tk/community/tcl2010/</a>.</dl>

<dl> <dt> <strong>Linux Kernel Summit</strong> <dd>
November 1-2, 2010. Hyatt Regency Cambridge, Cambridge, MA<br />
<a href="http://events.linuxfoundation.org/events/linux-kernel-summit">http://events.linuxfoundation.org/events/linux-kernel-summit</a>.</dl>

<dl> <dt> <strong>LISA '10 - Large Installation System Administration Conference</strong> <dd>
November 7-12, San Jose, CA<br />
<a href="http://usenix.com/events/">http://usenix.com/events/</a>.</dl>

<dl> <dt> <strong>ARM Technology Conference</strong> <dd>
November 9-11, Convention Center, Santa Clara, CA<br />
<a href="http://www.arm.com/about/events/12129.php">http://www.arm.com/about/events/12129.php</a>.</dl>

</p>

<hr>

<a name="distro"></a>
<h2>Distro News</h2>
<h3><img alt="lightning bolt" src="../gx/bolt.gif">Red Hat Enterprise Virtualization 2.2 Integrates Server and Desktop</h3>

<p>From the RED HAT SUMMIT & JBOSS WORLD in June, Red Hat announced the 
general availability of Red Hat Enterprise Virtualization 2.2. In 
addition to providing the first release of Red Hat Enterprise 
Virtualization for Desktops, the 2.2 update includes new scalability 
capabilities, migration tools and features to expand the performance 
and security of the solution.</p>

<p>Red Hat Enterprise Virtualization 2.1, which introduced Red Hat 
Enterprise Virtualization for Servers, was released in November 2009. 
Designed as a foundation for the virtualization of Red Hat Enterprise 
Linux and Microsoft Windows, with Microsoft SVVP certification, as 
well as for cloud computing environments, Red Hat Enterprise 
Virtualization has gained momentum with customers, including Fujitsu, 
IBM and NTT Communications, for their cloud deployments. </p>

<p>"As enterprises look to move beyond initial server consolidation to a 
more pervasive datacenter-wide virtualization strategy, they are 
looking to Red Hat Enterprise Virtualization to provide leading 
scalability and economics," said Navin Thadani, senior director, 
Virtualization Business at Red Hat. "Already experiencing traction 
with server and cloud deployments, the solution expands its reach 
today with the delivery of our desktop virtualization management 
capabilities to help more customers to break down the barriers to 
virtualization adoption."</p>

<p>Red Hat Enterprise Virtualization for Desktops, introduced in today's 
2.2 update, allows customers to deploy Hosted Virtual Desktop (HVD) 
configurations, also known as Virtual Desktop Infrastructure (VDI), 
bringing scalable, centralized provisioning and management of their 
desktop systems. It provides a web-based connection broker that allows 
end users to access their hosted virtual desktops, coupled with the 
open source SPICE remote rendering technology, which offers a rich 
multimedia experience, including multiple monitors, HD-quality video 
and bi-directional audio/video for video conferences. Other features, 
such as templating, thin provisioning and desktop pooling, are also 
included. Red Hat Enterprise Virtualization for Desktops supports 
Microsoft Windows XP, Windows 7 and Red Hat Enterprise Linux Desktop.</p>

<p>With the 2.2 release, Red Hat Enterprise Virtualization also features 
industry-leading scalability, supporting guests with up to 16 virtual 
CPUs and 256 gigabytes of memory per virtual machine. The release 
additionally provides new virtual machine conversion capabilities 
through a V2V tool designed to automate the conversion of VMware or 
Xen virtual machines for use within Red Hat Enterprise Virtualization. 
To further simplify moving virtual machine images between 
environments, Red Hat Enterprise Virtualization 2.2 also includes the 
ability to import and export virtual machine images and templates with 
the Open Virtualization Format (OVF).</p>

<p>"With today's announcement of Red Hat Enterprise Virtualization 2.2, 
customers can utilize the Cisco Unified Computing System and the 
Virtual Interface Card to drive virtualization efficiency through 
Cisco's extended memory and I/O virtualization technology," said Ed 
Bugnion, vice president and chief technology officer for Cisco's 
Server Access & Virtualization Business Unit. "We look forward to 
continued collaboration with Red Hat to offer our customers more 
choices, allowing them to take advantage of virtualization in their 
datacenter infrastructures."</p>

<p>"This release of Red Hat Enterprise Virtualization is a major 
milestone toward establishing KVM as a world-class open source 
hypervisor," said Bob Sutor, vice-president of Linux and Open Source 
at IBM. </p>

<p>Red Hat Enterprise Virtualization 2.2 is globally available today. To 
learn more about Red Hat Enterprise Virtualization, visit 
<a href="http://www.redhat.com/rhev">http://www.redhat.com/rhev</a>.</p>


<h3><img alt="lightning bolt" src="../gx/bolt.gif">openSUSE 11.3 is Out</h3>

<p>The openSUSE Project has announced the release of the openSUSE 11.3, 
with support for 32-bit and 64-bit systems. openSUSE 11.3 has new 
features and updates including SpiderOak to sync files across the 
Internet for free, Rosegarden for free editing audio files, improved 
indexing with Tracker, and updates to Mozilla Firefox, and 
Thunderbird.</p>

<p>Among these new features, openSUSE also provides support for netbooks 
and the Btrfs file system. Users can expect to see improved hardware 
support with the 2.6.34 Linux kernel and updated graphics drivers. And 
there is support for the next generation of interactive touchscreens 
like the HP TouchSmart.</p>

<p>openSUSE continues to deliver the popular KDE, GNOME and Xfce desktop 
environments, and now also provides the lightweight LXDE desktop 
environment. GNOME uses the 2.30.1 version and a preview of the 
upcoming GNOME 3.0. Or choose to use KDE SC 4.4.4.</p>

<p>The openSUSE community also announced the availability of openSUSE 
Edu: Linux for Education (or Li-f-e). Li-f-e is built on openSUSE 11.3 
but also provides education and development resources for parents, 
students, teachers as well as IT admins running labs at educational 
institutions. It comes bundled educational software covering subjects 
such as IT, mathematics, chemistry, astronomy, electronics, etc.</p>

<p>The next release will be openSUSE 11.4 in March, 2011.</p>

 
 
<h3><img alt="lightning bolt" src="../gx/bolt.gif">IBM Announces Open Beta Program AIX 7</h3>

<p>IBM has announced an open beta program for AIX 7, the company's open 
standards-based UNIX operating system. AIX 7 builds on the 
capabilities of previous releases of AIX and can use the energy 
management capabilities of the new POWER7 servers.</p>

<p>AIX 7 provides full binary compatibility for programs created on 
earlier versions of AIX including AIX 6, AIX 5, and 32-bit programs 
created on even earlier versions of AIX. This means that clients can 
protect previous investments in Power Systems by moving existing 
applications up to AIX 7 without having to recompile them. AIX 7 will 
also be supported on systems based on earlier generations of 
processors including POWER6, POWER5, and POWER4.</p>

<p>Many clients running prior generations of POWER hardware would like to 
consolidate on newer, more efficient POWER7 servers, but simply do not 
have the administrative resources to upgrade a large number of 
servers. AIX 7 introduces new technology to help simplify 
consolidation of these older workloads onto new systems. Clients can 
back up an existing AIX 5.2 environment and restore it inside of a 
Workload Partition on AIX 7, which can allow them to quickly take 
advantage of the advances in POWER technology.</p>

<p>Some of the key features of AIX 7 include:</p>

<p> * New support for very large workloads with up to 256 cores/1024 
 threads in a single AIX logical partition - four times greater than 
 that of AIX 6;<br />
 * Built-in clustering to simplify configuration and management of 
 multiple AIX systems for high availability;<br />
 * Simplified AIX configuration management for pools of AIX systems.</p>

<p>"The planned release of AIX 7 underscores the IBM commitment to 
continued UNIX innovation. ...Building on the success of AIX 6's open 
beta that helped hundreds of ISV's deliver certified applications at 
general availability, our AIX 7 open beta will help deliver smarter 
applications as well." said Jeff Howard, director of marketing for IBM 
Power Systems.</p>

<p>The beta program is open to all, and is designed to provide clients 
and independent software vendors (ISVs) with early access to the AIX 7 
operating system. Clients and other interested parties can participate 
in the beta by visiting ibm.com/aix and following the links to the 
open beta Web page at 
<a href="http://www14.software.ibm.com/iwm/web/cc/earlyprograms/websphere/aix7ob/">http://www14.software.ibm.com/iwm/web/cc/earlyprograms/websphere/aix7ob/</a>.
The beta code is packaged as a DVD ISO image that beta 
participants can burn to physical media.</p>


<h3><img alt="lightning bolt" src="../gx/bolt.gif">PC-BSD 8.1 Released</h3>
<p>The PC-BSD Team has released PC-BSD 8.1 (Hubble Edition) with KDE 
4.4.5  Version 8.1 contains a number of enhancements and improvements. 
For a full list of changes, please refer to the changelog at 
<a href="http://www.pcbsd.org/content/view/163/content/view/170/11/">http://www.pcbsd.org/content/view/163/content/view/170/11/</a>.</p>
 
<p>Some of the notable changes are:<br />
* KDE 4.4.5;<br />
* Numerous fixes to the installation backend;<br />
* Support for creating dedicated disk GPT partitioning;<br />
* Improved ZFS support;<br />
* Bugfixes to desktop tools / utilities.</p>

<p>Version 8.1 of PC-BSD is available for download from 
<a href="http://www.gotbsd.net">http://www.gotbsd.net</a>.</p>

<a name="commercial"></a>
<hr>
<h2>Software and Product News</h2>

<h3><img alt="lightning bolt" src="../gx/bolt.gif">Mozilla releases first Firefox 4 beta</h3>

<p>The Mozilla development team has released the first beta for version 
4.0 of the Firefox web browser.  Changes include better HTML 5 support 
and UI improvements.</p>

<p>According to Firefox development director Mike Beltzner, this beta is 
aimed at providing "an early look at what's planned" for the browser 
update. Firefox 4 will be the next major release of Mozilla's popular 
open source browser and will include a number of improvements, updates 
and new features.</p>

<p>Firefox 4 Beta 1 is based on version 2.0 of the Gecko rendering 
platform - the Firefox 3.6 branch uses Gecko 1.9.2 - and features a 
new Add-ons Manager and extension management API, and a number of 
Windows only changes, such as a new default 'tabs on top' layout for 
Windows systems. Mac OS X and Linux systems will receive the new tabs 
on top layout in a future update "when the theme has been modified to 
support the change". Other Windows improvements include a new Firefox 
Button on Vista and Windows 7 systems, replacing the menu bar, and an 
experimental Direct2D rendering back end - currently disabled by 
default.</p>

<p>Other changes include API improvements for JS-ctypes, a new HTML5 
parser, more responsive page rendering, support for additional HTML5 
form controls and partial support for CSS Transitions. User interface 
(UI) updates include a new default Bookmarks Button that replaces the 
Bookmarks Toolbar and a new single button for stop and reload. Native 
support for the HD HTML5 WebM / VP8 video format and full support for 
WebGL - a JavaScript binding to OpenGL ES 2.0 with industry support 
from Google, Mozilla and Opera - (currently disabled by default) have 
also been added.</p>

<p>Originally introduced in Firefox 3.6.4, version 4.0 includes enhanced 
crash protection technology from the Mozilla Lorentz Project. This is 
aimed at bringing full process isolation to Firefox, separating web 
pages and plug-ins from the main browser by running them in their own 
processes. Crash protection is now supported on Windows, Mac OS X and 
Linux, and currently protects the browser against crashes in the Adobe 
Flash, Apple QuickTime or Microsoft Silverlight plug-ins.</p>

<p>Beltzner notes that the developers plan to release a new beta version 
"every two to three weeks". A first release candidate (RC) for Firefox 
4 is currentlyscheduled to arrive in October of this year. A final 
release date, however, has yet to be confirmed.</p>

<p>Firefox 4.0 Beta 1 is available to download for Windows, Mac OS X and 
Linux. The latest stable release of Firefox is version 3.6.6 from the 
end of June.</p>

<p>Firefox binaries are released under the Mozilla Firefox End-User 
Software License Agreement and the source code is released under 
disjunctive tri-licensing that includes the Mozilla Public Licence, 
GPLv2 and LGPLv2.1.</p>

<h3><img alt="lightning bolt" src="../gx/bolt.gif">Apache Announces Tomcat Version 7.0</h3>
  
<p>The Apache Software Foundation (ASF) announced Version 7.0 release of 
Apache Tomcat, the award winning Open Source Java Application Web 
server. One of the ASF's earliest projects, the Tomcat code base was 
first donated to the ASF in 1999; the first Apache release, v.3.0, was 
made later that year. Apache Tomcat 7 is the project's first major 
release since 2006, fully implementing the Java Servlet 3.0, 
JavaServer Pages (JSP) 2.2, and Expression Language (EL) 2.2 
specifications for easier Web framework integration.</p>
 
<p>Tomcat 7 provides out-of-the-box support for development features that 
would otherwise be coded manually.  Apache Tomcat is shepherded by 
dozens of volunteers who contribute updates to its code base; its 
day-to-day operations, including community development and product 
releases, are overseen by a Project Management Committee.</p>
 
<p>With more than 10 million downloads to date, Apache Tomcat powers a 
broad range of mission-critical Websites and applications across 
multiple industries and use cases, from Fortune 500 conglomerates to 
service providers to eCommerce systems.</p>
  
<p>"I am delighted to see this first release of Apache Tomcat 7. Tomcat 
has always been the most popular deployment platform for Spring-based 
applications and this new release adds some great production 
technology," says Rod Johnson, general manager of the SpringSource 
division of VMware. "Tomcat's small footprint and reliable execution 
make it the ideal choice for the runtime component of SpringSource's 
tc Server. These features are also proving particularly important as 
organizations move their workloads to the cloud."</p>
 
<p>Developers using Tomcat 7 will also benefit from improved memory leak 
detection and prevention and support for 'aliasing' directories into 
an application's URL space. All known bugs reported in previous 
versions of Tomcat have been fixed in v.7.0.</p>
 
<p>Tomcat versions 5.5.x and 6.0.x will continue to be supported, 
however, bug fixes or updates to possible security vulnerabilities in 
earlier versions may be slightly delayed.</p>
 
<p>Tomcat 7 is released under the Apache Software License v2.0. 
Downloads, documentation, and related resources are available at 
<a href="http://tomcat.apache.org/">http://tomcat.apache.org/</a>.</p>

<h3><img alt="lightning bolt" src="../gx/bolt.gif">Suricata: Free intrusion detection & prevention engine</h3>

<p>The Open Information Security Foundation(OISF) has released version 
1.0 of its open source intrusion detection and prevention engine - 
Suricata.  Unlike Snort, another popular open source network intrusion 
prevention and detection system, Suricata runs multi-threaded and 
offers a number of advanced configuration options.</p>

<p>This first stable release includes a number of improvements and new 
features over the previous development releases, such as support for 
DCERPC (Distributed Computing Environment / Remote Procedure Calls) 
over UDP and the tag keyword. Additionally, CUDA (for Compute Unified 
Device Architecture) issues were fixed and it's performance was 
improved.</p>

<p>The OISF is funded by several US agencies, such as the Department of 
Homeland Security's Directorate for Science and Technology HOST 
program (Homeland Open Security Technology) and various members of the 
OISF Consortium, including a number of specialist IT security 
companies.</p>

<p>Suricata 1.0 source is available to download from the foundation's web 
site and is licensed under version 2 of the GNU General Public License 
(GPLv2). The sourc courd can be used for
Linux/FreeBSD/UNIX, Mac, and Windows platvorms.</p>
 
<p>For more info see: <a href="http://www.openinfosecfoundation.org/">http://www.openinfosecfoundation.org/</a>.</p>

<h3><img alt="lightning bolt" src="../gx/bolt.gif">Apache Announces Cayenne Version 3.0</h3>

<p>Version 3.0 release of Apache Cayenne, an easy-to-use, Open Source 
Java framework for object relational mapping (ORM) and persistence 
services and caching, was released in July.</p>

<p>In development for nearly 10 years, and an Apache Top-Level Project 
since 2006, Apache Cayenne is designed for high-demand applications 
and Websites accessed by millions of users each day. Cayenne is used 
by the Law Library of Congress, the world's largest publicly-available 
legal index.</p>

<p>The Apache Cayenne Project Management Committee has released a new 
Technical Fact Sheet detailing the state of Cayenne, including dozens 
of technical features, release highlights, and the Project's future 
direction. The Cayenne v.3.0 Technical Fact Sheet is available at 
<a href="https://blogs.apache.org/foundation/entry/apache_cayenne_v_3_0">https://blogs.apache.org/foundation/entry/apache_cayenne_v_3_0</a>.</p>

</div>

<hr>


<br clear="all" />

<table align='center' cellspacing='10'>
<tr>
<td>
<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/177/lg_bytes.html';
digg_title = 'News Bytes';
digg_bodytext = '<p>In this month\'s Linux Gazette, \'News Bytes\' covers the following topics:<br>Contents:<br>Rackspace and NASA Open Source Cloud Platform<br>Marvell Open-sources Easy Plug Computer Installer<br>MeeGo Platform Chosen by the GENIVI Alliance<br>OpenDocument 1.2 available for review for 60 days<br>Red Hat Enterprise Virtualization 2.2 Integrates Server and Desktop<br>openSUSE 11.3 is Out<br>IBM Announces Open Beta Program AIX 7<br>PC-BSD 8.1 Released<br>Mozilla releases first Firefox 4 beta<br>Apache Announces Tomcat Version 7.0<br>Suricata: Free intrusion detection & prevention engine<br>Apache Announces Cayenne Version 3.0<br></p>';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>
</td>
<td>
<a name="fb_share" type="box_count" href="http://www.facebook.com/sharer.php">Share</a>
<script src="http://static.ak.fbcdn.net/connect.php/js/FB.Share" type="text/javascript"></script>
</td>
<td>
<a href="http://twitter.com/home?status=Currently%20reading:%20http://linuxgazette.net/177/lg_bytes.html%20at%20Linux%20Gazette%20%23linuxgazette" title="Click to share this post on Twitter"><img src="../gx/twitter.png" width="50" height="85" border="0"></a>
</td>
</tr>
</table>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:177/lg_bytes.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<hr>
<p>
<img align="left" alt="[BIO]" src="../gx/authors/dokopnik.jpg" class="bio">
</p>

<em>
<p>
Deividson was born in Uni&atilde;o da Vit&oacute;ria, PR, Brazil, on
 14/04/1984. He became interested in computing when he was still a kid,
 and started to code when he was 12 years old. He is a graduate in
 Information Systems and is finishing his specialization in Networks and
 Web Development. He codes in several languages, including C/C++/C#, PHP,
 Visual Basic, Object Pascal and others.
</p>

<p>
Deividson works in Porto Uni&atilde;o's Town Hall as a Computer
 Technician, and specializes in Web and Desktop system development, and
 Database/Network Maintenance.
</p>



</em>

<br clear="all">


	<!-- *** BEGIN bio *** -->
<hr>
<p>

<img align="left" alt="Bio picture" src="../gx/authors/dyckoff.jpg" class="bio">

<em>
<p>
Howard Dyckoff is a long term IT professional with primary experience at
Fortune 100 and 200 firms. Before his IT career, he worked for Aviation
Week and Space Technology magazine and before that used to edit SkyCom, a
newsletter for astronomers and rocketeers. He hails from the Republic of
Brooklyn [and Polytechnic Institute] and now, after several trips to
Himalayan mountain tops, resides in the SF Bay Area with a large book
collection and several pet rocks.
</p>

<p>
Howard maintains the <a
href="http://technology-events.blogspot.com">Technology-Events</a> blog at
blogspot.com from which he contributes the Events listing for Linux
Gazette. Visit the blog to preview some of the next month's NewsBytes
Events.
</p>

</em>
<br clear="all">
<!-- *** END bio *** -->

<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2010, <a href="../authors/dokopnik.html">Deividson Luiz Okopnik</a> and <a href="../authors/dyckoff.html">Howard Dyckoff</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 177 of Linux Gazette, August 2010
</p>

</div>
</div>


<div class="content lgcontent">

<a name="borisov"></a>
<h1>A way to connect an iPod Touch to a MIPSnetbook</h1>
<p id="by"><b>By <a href="../authors/borisov.html">Anton Borisov</a></b></p>

</b>
</p>

<p>
<h3>Introduction</h3>

<p>
A couple years ago, I had a chance to work with industrial MIPS-based VME
boards. It was so unusual to see that the modern failure-proof world
actually extends beyond x86-architecture. Those VME boards had a Linux
distrubution running, so no special knowledge was required to log in, and
perform a task. Being designed for industrial purposes, it would be
irrational to buy it for home use - so when I heard about a Chinese
hardware company named Lemote <a href="#borisov.html_1">[1]</a>, which has
MIPS-based products in its portfolio, my first thought was
- &quot;Those guys have what I need - MIPS netbooks. I want it here, by my
side&quot;. That's how the story began. 
</p>

<p>
If you're a reasonably literate user of GNU/Linux system, then your
experience with any netbook should be quite smooth - just as it was for me.
As a matter of fact, the Yeeloong netbook has Debian preinstalled, with
repositories tuned to update the &quot;lenny&quot; release. My first step
was to upgrade Debian to the latest packages available. It's generally nice
to have the most recent applications, the important ones in my case being
gcc and building tools. 
</p>

<h3>Connecting to iPod via iTunnel transport</h3>
<p>
Apple fans should know that to synchronize/copy files to an iPod or iPhone,
an average user needs to have iTunes installed on a PC.  It's ludicrous,
but iTunes is only available for Mac OS/X and Windows - and the most
ludicrous thing about iTunes is that it's compiled for x86 architecture
only. No more PowerPC, only x86/x86_64. Should I even bother mentioning
Linux and MIPS here? 
</p>

<p>
I have an iPod Touch, second
generation. A very handy device, with multi-touch and mobile Safari
to surf the net via Wi-Fi. However, I faced a tough problem - how do
I copy audio and video files onto it without Microsoft Windows and
iTunes, i.e., directly from Linux?  There is a solution, actually - you
might be interested in doing a <em>jail-break</em> for your iPod, in order to
install an SSH server and make a direct connection by means of SSHFS<a id="borisov.html_2_back"></a><a href="#borisov.html_2">[2]</a>
</p>

<p>
While writing about performing a jail-break is beyond the scope of
this article, I can gladly tell you - it was scary, but at the end, I
had a wonderful feeling - <em>it works!</em>  And to cheer you up even
more, there is no  chance of turning your iPod into a brick. It's an
absolutely amazing device in terms of recovery and hardware design. 
</p>

<p>
Okay, back to basics. I managed
to flash an updated, i.e. 'JB' firmware with an activated SSH server.
Now, it was time to log into iPod's operating system. You can do it
via Wi-Fi network, or alternatively, via USB-cable by means of the
iTunnel <a id="borisov.html_3_back"></a><a href="#borisov.html_3">[3]</a> package. Let's see how it
works in practice. 
</p>

<p>
I grabbed the source code, and did a compilation. No external
dependencies or additional libraries were required. Kudos to
iTunnel and libiphone authors! 
</p>

<pre class="code">loongson@debian:~$ cd src/itunnel-0.0.9/
loongson@debian:~/src/itunnel-0.0.9$ make clean &amp;&amp; make</pre><p>

I'm an unprivileged user at Yeeloong netbook, so I decided to use
port 12022. 
</p>

<pre class="code">loongson@debian:~/src/itunnel-0.0.9$ ./itunnel 12022
get_iPhone() success
- successfully got device
server waiting for ssh connection on port 12022

server accepted connection, clientfd:5
client thread fd(5) running, server port 12022 , peer port 45964
tunnel now running.
SSH to localhost port 12022 to get to iPhone.
 (use ssh -D  to create SOCKS tunnel.)
do Ctrl+C to quit the server (can take a few seconds).</pre><p>

Well, everything's ready to login to iPhoneOS. Let's get to it. Don't
forget about default password though: every Apple device seems to
have a built-in 'mobile' user with password set to 'alpine'. 
</p>

<pre class="code">loongson@debian:~/src/itunnel-0.0.9$ ssh -l mobile -p 12022 localhost
mobile@localhost's password:
localhost:~ mobile$ uname -a
Darwin localhost 9.4.1 Darwin Kernel Version 9.4.1: Mon Dec  8 21:02:57 PST 2008; root:xnu-1228.7.37~4/RELEASE_ARM_S5L8720X iPod2,1 arm N72AP Darwin</pre><p>

Quite the usual Linux environment, almost all user-space utilities have
been ported from the bigger PCs: 
</p>

<p>
uptime... 
</p>

<pre class="code">localhost:~ mobile$ uptime
 23:14pm  up 17 days 22:28,  1 user,  load average: 0.10, 0.11, 0.08</pre><p>

df... 
</p>

<pre class="code">localhost:~ mobile$ df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/disk0s1          750M  475M  268M  64% /
devfs                  17K   17K     0 100% /dev
/dev/disk0s2           15G   15G  250M  99% /private/var</pre><p>

top, and many others...
</p>

<pre class="code">Processes:  23 total, 1 running, 22 sleeping... 81 threads
Load Avg:  0.05,  0.09,  0.08    CPU usage:  3.70% user,  5.56% sys, 90.74% idle
SharedLibs: num =    0, resident =     0 code,     0 data,     0 linkedit.
MemRegions: num =  3000, resident =   40M +     0 private,   32M shared.
PhysMem:   26M wired,   16M active, 8448K inactive,  114M used, 1704K free.
VM: 583M + 0   251397(0) pageins, 2080(0) pageouts

  PID COMMAND      %CPU   TIME   #TH #PRTS #MREGS  RPRVT  RSHRD  RSIZE  VSIZE
 1599 top          7.4%  0:00.62   1    17     50   580K   848K  1348K    12M
 1592 bash         0.0%  0:00.12   1    13     42   340K   480K  1120K    13M
 1591 sshd         0.0%  0:00.50   1    14     37   368K   260K  1324K    13M
 1583 ptpd         0.0%  0:00.30   2    48     75   544K  1472K  1372K    14M
 1540 MobileSafa   0.0%  1:31.78   5   170    428 15832K    17M    37M    97M
   43 locationd    0.0%  0:56.46   9   100    141  1272K  1908K  1908K    29M
   32 fairplayd    0.0%  0:00.28   1    31     64   512K  1372K   512K    15M
   31 iapd         0.0%  0:40.24   9   116    156  1248K  2760K  1568K    30M
   30 mediaserve   0.0% 31:38.90   9   153    245  1820K  1944K  2292K    39M
   29 lockdownd    0.0%  0:03.25   3    62     99   876K  1792K   960K    26M
   28 update       0.0%  0:15.56   1    13     41   216K   624K   228K    11M
   26 sbsettings   0.0%  0:00.19   1    27    107   868K  2592K   856K    25M
   25 Navizon      0.0%  0:11.34   1    38    162  1280K  2924K  1396K    26M
   24 msd          0.0%  0:38.88   1    32     95  1192K  1656K  1240K    15M
   23 mslocd       0.0%  0:26.59   1    32     97   632K  1880K   788K    23M
   19 CommCenter   0.0%  0:04.97   4    83     90   848K  1764K   940K    25M
   17 BTServer     0.0%  0:01.18   2    66     93   636K  1556K   668K    17M
   16 SpringBoar   1.8% 59:16.65  13   325    689  9060K    17M    20M    86M
   15 configd      0.0%  6:28.52   5   160    127  1020K  1580K  1488K    16M
   14 syslogd      0.0%  1:17.33   4    37     35   320K   248K   444K    13M
   13 notifyd      0.0%  0:35.43   2   247     27   232K   248K   260K    12M
   12 mDNSRespon   0.0%  2:00.59   2    46     65   616K  1360K   912K    14M
    1 launchd      0.0%  0:40.65   3    78     35   284K   248K   396K    12M</pre><p>

Of course, switching to a higher level via the 'su' command allows you to
see even more information. For instance, all the logging information
about the Wi-Fi network iPod has managed to connect to is available
through 'dmesg' output: 
</p>

<pre class="code">AppleBCM4325::setASSOCIATE() [configd]:  lowerAuth = AUTHTYPE_OPEN, upperAuth = AUTHTYPE_NONE, key = CIPHER_NONE, flags = 0x2
AppleBCM4325 Joined BSS:     BSSID = 00:14:d1:4b:e6:f7, adjRssi =  44, rssi = -46, rate = 54 (100%), channel =  1, encryption = 0x1, ap = 1, hidden = 0, directed = 0, failures =   0, age = 1, ssid = &quot;my_net&quot;
AirPort: Link Up on en0</pre><p>

Having SSH server up and running on the iPod Touch gives us the ability
to connect to it via SSHFS-connection. Let's mount iPod' storage now!
</p>

<pre class="code">loongson@debian:~$ sudo sshfs -p 12022 -o allow_other mobile@localhost:/private/var /media/usb
mobile@localhost's password:
loongson@debian:~$ df
Filesystem           1K-blocks      Used Available Use% Mounted on
/dev/hda1             57685532  46146588   8608692  85% /
tmpfs                   514464         0    514464   0% /lib/init/rw
udev                     10240      3552      6688  35% /dev
tmpfs                   514464         0    514464   0% /dev/shm
mobile@localhost:/private/var
                     15324954624 15062839296 262115328  99% /media/usb</pre>


<p>
Now, let's do some simple benchmarking - copy a single file from
iPod Touch to a netbook's local filesystem: 
</p>

<pre class="code">loongson@debian:~$ rsync -v /media/usb/mobile/Media/mp3/Madonna/greatest_hits/106\ Crazy\ For\ You.mp3 .
106 Crazy For You.mp3

sent 5859015 bytes  received 31 bytes  1065281.09 bytes/sec
total size is 5858218  speedup is 1.00</pre><p>

About 1MiB/s - that's pretty fast. 
</p>

<p>
And let's perform the backward operation, i.e. copy a single file
from netbook to iPod: 
</p>

<pre class="code">loongson@debian:~$ rsync -v --progress ./wine-1.1.23.tar.bz2 /media/usb/mobile/Media/
wine-1.1.23.tar.bz2
    11075584  71%  140.08kB/s    0:00:30</pre><p>

Frustrating, isn't it? What reasonable explanation could there be?
Well, I guess the bottleneck is that the performance of iPod's CPU -
ARM processor clocked at 533 MHz could be too slow to handle encrypted
SSH packets. What should I do? Simply login to iPod, and secure copy
a necessary file from a host (i.e., Yeeloong) machine. Like this: 
</p>

<pre class="code">localhost:~ mobile$ scp loongson@10.10.1.1:/home/loongson/Kylie* .
loongson@10.10.1.1's password:
Kylie Minogue - Je Ne Sais Pas Pourquoi.mp3             100% 5655KB   1.1MB/s   00:05</pre><p>

<em>Voila</em> - it works! The same bandwidth in both directions!
</p>

<h3>Conclusion</h3>
<p>
The approach of performing a jail-break first, and then attaching
iPod's storage to PC via SSHFS is a long way to go for something so simple.
But - and this is essential - Linux users have no other means of
transferring files to the iPod, due to a) iTunes being available for
Mac- and Windows-platforms only; b) iTunes being compiled against x86
CPU only (PowerPC/SPARC/MIPS/ARM Linux users should wave "bye-bye"!), and
c) there being no means to log onto an iPod without the SSH
server being pre-installed. On the other hand, once you have done so,
you have a full control over your lovely iPod Touch. 
</p>

<h3>References</h3>
<p>
<a id="borisov.html_1"></a><a href="#borisov.html_1_back">[1]</a>
<a href="http://www.lemote.com/en/products/">http://www.lemote.com/en/products/</a><br>
<a id="borisov.html_2"></a><a href="#borisov.html_2_back">[2]</a>
<a href="http://fuse.sourceforge.net/sshfs.html">http://fuse.sourceforge.net/sshfs.html</a><br>
<a id="borisov.html_3"></a><a href="#borisov.html_3_back">[3]</a>
<a href="http://www.cs.toronto.edu/~jingsu/itunnel/">http://www.cs.toronto.edu/~jingsu/itunnel/</a>
</p>


<br clear="all" />

<table align='center' cellspacing='10'>
<tr>
<td>
<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/177/borisov.html';
digg_title = 'A way to connect an iPod Touch to a MIPSnetbook';
digg_bodytext = '<p> A couple years ago, I had a chance to work with industrial MIPS-based VME boards. It was so unusual to see that the modern failure-proof world actually extends beyond x86-architecture. Those VME boards had a Linux distrubution running, so no special knowledge was required to log in, and perform a task. Being designed for industrial purposes, it would be irrational to buy it for home use - so when I heard about a Chinese hardware company named Lemote [1], which has MIPS-based products in its portfolio, my first thought was - &quot;Those guys have what I need - MIPS netbooks. I want it here, by my side&quot;. That\'s how the story began.  </p> ';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>
</td>
<td>
<a name="fb_share" type="box_count" href="http://www.facebook.com/sharer.php">Share</a>
<script src="http://static.ak.fbcdn.net/connect.php/js/FB.Share" type="text/javascript"></script>
</td>
<td>
<a href="http://twitter.com/home?status=Currently%20reading:%20http://linuxgazette.net/177/borisov.html%20at%20Linux%20Gazette%20%23linuxgazette" title="Click to share this post on Twitter"><img src="../gx/twitter.png" width="50" height="85" border="0"></a>
</td>
</tr>
</table>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:177/borisov.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<hr>
<p>
<img align="left" alt="[BIO]" src="../gx/authors/borisov.jpg" class="bio">
</p>

<em>
<p>
Anton jumped into Linux world in 1997, when he first tried a tiny
 muLinux distribution, being run from a single floppy. Later on, Red Hat
 and Slackware became his favorite choice. Nowdays, Anton designs
 Linux-oriented applications and middleware, and prefers to work with
 hardware labeled as "Powered by Linux".
</p>



</em>

<br clear="all">


<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2010, <a href="../authors/borisov.html">Anton Borisov</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 177 of Linux Gazette, August 2010
</p>

</div>
</div>


<div class="content lgcontent">

<a name="dyckoff"></a>
<h1>Away Mission: SemTech 2010 - Summary</h1>
<p id="by"><b>By <a href="../authors/dyckoff.html">Howard Dyckoff</a></b></p>

</b>
</p>

<p>

<p>
Almost 1200 people attended this year's Semantic Technology Conference
(SemTech 2010) in San Franciso.  That was a big jump from last year and
probably due in equal parts to the move to San Francisco and also the
growing use of SemTech all over the web. Remember, this is a recession
year.
</p>

<p>
Where do we find RDF and SemTech? The US government and maybe European
governments.  Semantic annotations are being added to many public
databases.  Also, the latest HTML5 draft has RDFa support in it.  And who
uses Semantic Technology now on the Web?  The BBC, Newsweek, the NY Times
and even companies like Best Buy have everyday applications running on
SemTech.  In short, Semantic Technology is everywhere.  (Visit the earlier
Away Mission that describes the basics of the Semantic Web <a
href="../129/dyckoff.html">here</a>.)
</p>

<p>
The event bills itself as the world's largest conference on
semantic technologies. It is also focused on the commercial aspects of
developing semantic technologies and incorporating these into social,
business and government processes.
</p>

<p>
One new aspect of the conference, which showed the pervasiveness of
Semantic Technology, was the large number of vertical industry tracks. There
were tracks for Open Government, Enterprise Data Management, Health-care
and Life Sciences, SOA Governance, Publishing, Advertising and Marketing,
and Semantic Web Technologies.
</p>

<p>
The other interesting trend was the focus on automated metadata extraction
and the automation of ontology and taxonomy building.  This was reflected
on the expo floor and in the number of presentations discussing this new
level of automation.
</p>

<p>
While there were few vendors - many of last year's vendors had been snapped
up as divisions of larger companies - the offerings were richer and more
mature. This was echoed in the conference by the frequent discussions
of monetization and business models. I'll address that in a few
paragraphs.
</p>


<p>
SemTech 2010 ran Monday through Friday, with intro sessions Monday evening
and tutorials all day Tuesday. The Friday tracks changed a bit from
primarily vendor-sponsored user sessions of previous years. For one
example, there was a hands-on tutorial on Drupal 7 and RDFa open to any
conference attendee.  The slides from that session are on SlideShare at
<a href="http://www.slideshare.net/scorlosquet/how-to-build-linked-data-sites-with-drupal-7-and-rdfa">http://www.slideshare.net/scorlosquet/how-to-build-linked-data-sites-with-drupal-7-and-rdfa</a>
</p>

<p>
Drupal is a widely-used open source platform for publishing and managing
content.  Version 7 is almost released and it will use RDFa for storing
site and content metadata. Drupal 7 will have RDFa enabled by default for
metadata on all nodes and comments. The key point here is the increasing
commonality of RDFa functionality in new websites and site building tools.
That emerging ubiquity will build the Semantic Web of meaning that Tim
Berners-Lee spoke about almost a decade ago.
</p>  

<p>
Just in the last few months, a new working group was formed for RDFa at the
W3C with the goal of defining additional structure in HTML files for
additional metadata. The group is working on linking RDFa into HTML5 and
XHTML5 as well as the Open Document format used by OpenOffice. As an
international example,  the UK's e-government effort plans to use RDFa
throughout its web pages. This allows the data to be read within a context
and used with that context preserved.
</p>

<p>
The Open Graph used within the FaceBook web site is a simplified form of
RDFa and the adoption of Open Graph by other social web sites allows
RDF-based sharing of semantic information.  For more info in Open Graph,
check out this presentation on SlideShare, which is similar to one made at
SemTech 2010:
</p>

<p>
I should mention here that several of the technical presentations from
SemTech 2010 and 2009 are on SlideShare and can be searched for  with the
string "semtech" to find them.
</p>  

<h3>Purchasing SemTech Companies</h3>

<p>
A few weeks before this year's SemTech, Apple purchased SIRI, one of the
bright stars from SemTech 2009.  SIRI's intelligent semantic agent for
desktops and mobile devices, which mixed location-based services, mashups,
and voice recognition with an inference engine, was a hit with the SemTech
crowd and I had been looking forward to a forward looking progress report.
</p>  

<p>
From the Semantic Universe review of the SIRI sale: "SIRI was in the
vanguard of leveraging the AI-based apps and applications that relate to
the semantic web developed by SRI"  and "one of the core and most
innovative technologies coming out of SRI - which led the 'CALO: Cognitive
Assistant That Learns and Organizes' DARPA project.
Maybe what's most important about SRI and CALO's Active Ontologies
innovation... was to create passive inferencing that... lets one reach
conclusions and drive to actions based on those conclusions."  More Semantic
Universe reviews of the SIRI sale can be found here:
<a href="http://www.semanticweb.com/on/apple_buys_siri_once_again_the_back_story_is_about_semantic_web_159896.asp">http://www.semanticweb.com/on/apple_buys_siri_once_again_the_back_story_is_about_semantic_web_159896.asp</a>
</p>

<p>
Catch the SIRI video embedded there - or go directly to
<a href="http://www.youtube.com/watch?v=MpjpVAB06O4">http://www.youtube.com/watch?v=MpjpVAB06O4</a>.
</p>

<p>
Of course, just after this year's SemTech event, Google bought Metaweb, the
force behind the important FreeBase global semantic data store. On the
company blog, Google wrote: "Working together, we want to improve searching
and make the web richer and more meaningful for everyone."
</p>

<p>
They also wrote: "Google and Metaweb plan to maintain Freebase as a free
and open database for the world. Better yet, we plan to contribute to and
further develop Freebase and would be delighted if other web companies use
and contribute to the data. We believe that by improving Freebase, it will
be a tremendous resource to make the web richer for everyone. And to the
extent the web becomes a better place, this is good for webmasters and good
for users."
</p>

<p>
One immediate benefit of the acquisition, Metaweb has increased the
frequency of Freebase down-loadable database dumps from quarterly to
weekly.
</p>

<p>
You can visit the YouTube intro to MetaWeb:
<a href="http://www.youtube.com/watch?v=TJfrNo3Z-DU&amp;feature=youtu.be">http://www.youtube.com/watch?v=TJfrNo3Z-DU&amp;feature=youtu.be</a>
</p>

<p>
And, for more detail, view the "Introducing Freebase Acre 1.0" video:
<a href="http://www.youtube.com/watch?v=dF-yMfRCkJc">http://www.youtube.com/watch?v=dF-yMfRCkJc</a>
</p>

<h3>SemTech Code Camp</h3>

<p>
The FreeBase presentation was one of the best at the free Semantic Code
Camp held one evening during SemTech 2010. Delivered by Jamie Taylor, the
Minister of Information at Metaweb Technologies, it describe the project
that has over 12 million topics which can be queried by SPARQL and other
semantic protocols.  It gets the information from Wikipedia, the
government, SFMOMA, MusicBranz, and other sites providing semantic data.
It acts as a Rosetta Stone between identifiers in different systems such as
Netflix, Hulu, Fandango, etc. with 99% accuracy. All this runs on a
Creative Commons license.
</p>

<p>
You can find that FreeBase presentation here:
<a href="http://www.slideshare.net/jamietaylor/sem-tech-2010-code-camp">http://www.slideshare.net/jamietaylor/sem-tech-2010-code-camp</a>
</p>

<p>
Other Code Camp presenters included Andraz Tori from Zemanta, which can
read in most text from many domains and give back standard tags and
categories, Wen Ruan of Textwise, which uses faceted search to find and use
subsets of a data collection, and Tom Tague of OpenCalais, a project of
Thomson Reuters, which can categorize and tag the people, places,
companies, facts, and events in content.
</p>  

<p>
The Code Camp was a beginner's track on how to use Semantic Technology and an
open Unconference track. A nice aspect was that anyone registering through
the Silicon Valley Semantic Technology Meetup could attend for free and
also get an expo pass to SemTech and share in the preceding reception and
free margaritas.
</p> 
   

<h3>Google Rich Snippets</h3>

<p>
Google announced "Rich Snippets" just over a year ago in May 2009. Today,
if webmasters add structured data markup to their web pages, Google can use
that data to show better search result descriptions.  This is not fully
implemented yet, but extra snippets are being captured and are showing up
in Google search results.  One example of this is the RDFa used in the
display of Google video selection results or receipes that display calories
and prep time on ther first line.
</p>

<p>
Kavi Goel and Pravir Gupta of Google described the simple markup vocabulary
used by Google for enhanced indexing. Currently, this can be in a micro
format or RDFa. They explained that they will add to the vocabulary as more
domains are added to the Rich Snippets ontology.  They will also be
expanding the vocabulary to include over 40 different languages, and 
will use the FaceBook Social Graph to link friends and locations.
</p>

<p>
They have just released a testing tool for webmasters and content
developers.  One reason for this:  most web sites were not doing the
snippet markup correctly.  The tool will show which elements are visible
and what properties are listed.  If nothing shows at all, then the site is
not using snippets correctly.
</p>  

<p>
Among the more common mistakes are the use of hidden text and markup
in-line, as Google search ignores this.  Alternatively, the person doing
the markup needs to be very clear in terminology.  They cited ambiguities
like differences in ratings versus reviews or votes versus counts. They
expect these to be cleared up with practice.  They also mentioned that
global use of snippets was growing at 4x the US rate from 10/09 to 06/10.
</p>


<h3>Web 3.0 Web Sites</h3>

<p>
The session on Building Web 3.0 Web Sites  discussed best practices in
implementing SEO, RDFa and semantic content for Web 3.0 sites.
</p>

<p>
The presenters - John Walker, Mark Birbeck, and Mark Windholtz - discussed
how to transform current content into semantically-rich web pages. They
emphasized the need to improve and maintain data quality, both for the main
content and for the tags and metadata that will enhance access and
combination. In addition they recommended the following:
</p>

<ul>
<li> use emerging standards like HTML 5, RDFa (and 'Google Rich Snippets'), WURFL, etc.
<li> establish robust user personas
<li> try to improve metadata throughout the site
<li> use existing ontologies or establish one or more as needed
<li> use web namespaces and URIs
<li> implement Triple stores and use REST web architecture
</ul> 

<p>
If working within a company, try to break down application silos and free
the data.  They suggested making data accessible by having triple stores
run 'on top' of existing databases.  It's much less expensive to do this and
needs less effort to start. Finally, it may be easier for IT departments to
accept semantic extensions when the underlying data resides in traditional
databases maintained by the usual staff.
</p>


<h3>Automatically Distilling Semantic Content</h3>

<p>
Several presentations focused on the emerging techniques for dynamically
extracting meaning and metadata and mapping text information into
taxonomies and ontologies.  These include combinations of statistical and
rules-based metadata extraction and auto-tagging and auto-classification to
link related content.
</p>

<p>
Some of this is being facilitated by running semantic projects that are
building standard vocabularies and standard ontologies.  Examples of this
are TextWise and FreeBase, as well efforts now taking place in industry
verticals.
</p>  

<p>
One presentation with a huge title was The Use of Semantic Analytics to
Achieve Data Transparency Using Government Standards for Information
Sharing, by Bill Stewart of Jeskell.  Stewart noted that almost half the
work week of a knowledge worker is spend finding needed information -- 19
hours a week!  Globally, we are collecting 15 petabytes every day and 80%
of new data is unstructured.  For the demo in his session, he showed the
Languageware  Workbench finding work roles from text information on the
Katrina recovery effort and distilling out an entity list of working teams.
The rule set had been built over a two day period parsing the text record.
</p>

<p>
In Assistive and Automatic Tools for Tagging and Categorizing Anything,
Seth Maislin did a survey of automation techniques.  Although the goal is
to save costs by getting human intervention out of loop, Maislin pointed
that domain expert intervention may be needed to review auto-indices and
auto-built ontologies.  Maislin suggested doing this toward the beginning
of a project to build trustworthy associations.  Building the index, with
or without the aid of a taxonomy, is the place for human involvement.  In
MedLine, humans assist categorization by accepting or declining initial
results, then reviewing and correcting by experts, added by active social
tagging by users.  He also recommended using open source taxonomies to
start and extend your own.
</p>



<h3>Nepomuk in KDE SC 4</h3>

<p>
Another example of the pervasiveness of SemTech is the Nepomuk project
which provides a standardized, conceptual framework for Semantic Desktops.
Part of the new tech in KDE SC 4, Nepomuk shares data from several desktop
applications using  RDF metadata. There are C/C++ and Java implementations.
</p>

<p>
Core development results will be publicly available during the project via
a webbased collaboration platform. The most prominent implementation is
available at <a href="http://nepomuk.kde.org">http://nepomuk.kde.org</a>.
</p>

<p>
Contributors to the project were in various expo booths, including the
folks from DERI.
</p> 

<p>
Here's part of the Goal statement from the Nepomuk project website:
"NEPOMUK intends to realize and deploy a comprehensive solution - methods,
data structures, and a set of tools - for extending the personal computer
into a collaborative environment, which improves the state of art in online
collaboration and personal data management...."<br>
<a href="http://nepomuk.semanticdesktop.org/xwiki/bin/view/Main1/Project+Objectives">http://nepomuk.semanticdesktop.org/xwiki/bin/view/Main1/Project+Objectives</a>
</p>

<p>
Although initially designed to fulfill requirements for the NEPOMUK
project, these ontologies are useful for the semantic web community in
general. These basically extends the search process with a  local desktop
RDF store and links data from various applications that use these KDE
ontologies.  The ontologies are open source and are used by Tracker in
GNOME.
</p>

<p>
The NEPOMUK ontologies are available from the following Web page:<br>
<a href="http://www.semanticdesktop.org/ontologies/">http://www.semanticdesktop.org/ontologies/</a>
</p>


<p>
In the last 2 years, the event organizer, Wilshire Conferences, has
organized SemTech and the related Enterprise Data World event with a 'lunch
on your own' policy except for the tutorial day. That, and the conference
tote bag, makes it a bit less expensive.  All attendees got an early
conference CD but conference web site hosts password access to updated
presentations.  By the way, that single lunch on the tutorial day was great!  The
Hilton kitchen staff produced tasty and eye-pleasing food.  And the move
from San Jose to the SF Hilton resulted in a better facility overall - an
excellent AV team kept all the rooms functional and all but one room had a
net of extension cords to power attendee laptops.
</p>  

<p>
I have to say I found SemTech sessions more satisfying and less academic
this year and more about real tools and products. I'm happy that they plan
to return the SF Hilton in 2011 hope to attend.   
</p>


<br clear="all" />

<table align='center' cellspacing='10'>
<tr>
<td>
<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/177/dyckoff.html';
digg_title = '';
digg_bodytext = '<p> Almost 1200 people attended this year\'s Semantic Technology Conference (SemTech 2010) in San Franciso.  That was a big jump from last year and probably due in equal parts to the move to San Francisco and also the growing use of SemTech all over the web. Remember, this is a recession year. </p> ';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>
</td>
<td>
<a name="fb_share" type="box_count" href="http://www.facebook.com/sharer.php">Share</a>
<script src="http://static.ak.fbcdn.net/connect.php/js/FB.Share" type="text/javascript"></script>
</td>
<td>
<a href="http://twitter.com/home?status=Currently%20reading:%20http://linuxgazette.net/177/dyckoff.html%20at%20Linux%20Gazette%20%23linuxgazette" title="Click to share this post on Twitter"><img src="../gx/twitter.png" width="50" height="85" border="0"></a>
</td>
</tr>
</table>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:177/dyckoff.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<!-- *** BEGIN bio *** -->
<hr>
<p>

<img align="left" alt="Bio picture" src="../gx/authors/dyckoff.jpg" class="bio">

<em>
<p>
Howard Dyckoff is a long term IT professional with primary experience at
Fortune 100 and 200 firms. Before his IT career, he worked for Aviation
Week and Space Technology magazine and before that used to edit SkyCom, a
newsletter for astronomers and rocketeers. He hails from the Republic of
Brooklyn [and Polytechnic Institute] and now, after several trips to
Himalayan mountain tops, resides in the SF Bay Area with a large book
collection and several pet rocks.
</p>

<p>
Howard maintains the <a
href="http://technology-events.blogspot.com">Technology-Events</a> blog at
blogspot.com from which he contributes the Events listing for Linux
Gazette. Visit the blog to preview some of the next month's NewsBytes
Events.
</p>

</em>
<br clear="all">
<!-- *** END bio *** -->

<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2010, <a href="../authors/dyckoff.html">Howard Dyckoff</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 177 of Linux Gazette, August 2010
</p>

</div>
</div>


<div class="content lgcontent">

<a name="grebler"></a>
<h1>Tunnel Tales 2</h1>
<p id="by"><b>By <a href="../authors/grebler.html">Henry Grebler</a></b></p>

</b>
</p>

<p>

<h3>Introduction</h3>

<p>
In a previous article, <A
HREF="../172/grebler.html">Tunnel Tales 1</A> I
described how to use SSH tunnels and a third machine to provide
network access from one machine to a second machine which was
otherwise not directly accessible. Today's scenario is quite
different.
</p>

<p>
We want convenient access to a machine which can only be reached by
navigating a chain of intermediate machines.
</p>

<p>
Whereas the earlier task could be accomplished with a single command,
the current task is far more formidable and requires more powerful
magic.
</p>

<p>
This article will assume that you are very familiar with SSH. I will
not repeat points I made in the earlier article.
</p>


<p>
<strong>Keywords</strong>: SSH tunnels, expect
</p>

<h3>The Scenario</h3>

<p>
Networks come in all shapes and sizes. I'm sure that the original
network was designed. I guess that, over time, a machine was added
here, another was removed there - much like a well loved suit might be
modified as its owner ages and changes shape.
</p>

<p>
By the time I arrived, the network was looking quite convoluted. It
was easy enough to get to the newer machines. But some of the legacy
machines required some serious tap-dancing before they could be
reached.
</p>


<div style="margin: 0px auto 10px; text-align:center" />
<a name="Diag1"></a> <img src="misc/grebler/diag_TT2_1.jpeg"
alt="Diagram 1" border="0">
</div>

<pre>
target	the machine I need to work on
jump1	an intermediate machine
jump2	another intermediate machine
laptop	my laptop
</pre>

<p>
If I only needed to get to the target machine once or twice, I would
just <tt>ssh</tt> from my laptop to <b>jump1</b>; then again from
there to <b>jump2</b>; and finally from there to the target machine.
</p>

<p>
But I knew that I would be visiting <b>target</b> many times over the
next week or two. And further, and more interestingly, I would need to
transfer files between my laptop and the target machine.
</p>

<p>
Again, for transferring files, most people would suggest in
exasperation to just transfer them from one machine to the next until
they reached the required destination.
</p>



<h3>Analysing the Task</h3>

This task provides an educational "compare and contrast" with the task
of the earlier article. 

<ul>
<li>The previous scenario was handled by a single <tt>ssh</tt>
command. It should be obvious that we will need several commands this
time.</li>

<li>The two endpoints previously were on remote machines (neither end
was on the laptop). This time the laptop constitutes one end of the
required tunnel.</li>

</ul>

<h3>The First Step</h3>

<p>
I invoke the following command on my laptop:

<pre class="code">
	ssh -L 9922:localhost:9822 jump1
</pre>
</p>

<p>
The command says to establish an SSH connection to
<strong>jump1</strong>. "While you're at it, I want you to listen on a
port numbered <strong>9922</strong> on <strong>localhost</strong> (ie
the laptop). If someone makes a connection to that port, connect the
call through to port <strong>9822</strong> on <strong>jump1</strong>."
</p>

<p>
Why <strong>9922</strong>? The port number is arbitrary, but I use the
form <strong>XX22</strong> to remind me that this relates to <tt>SSH</tt>.
</p>

<p>
Why <strong>9822</strong>? It seems that this port number is as
arbitrary as <strong>9922</strong>, but that's not entirely true.
We'll examine this a little later.
</p>

<p>
So far we have not achieved much.
</p>


<h3>The Second Step</h3>

The previous command landed me on <strong>jump1</strong>, where I now
issue the following command:

<pre class="code">
	ssh -L 9822:localhost:9722 jump2
</pre>
</p>

<p>
You should be able to work out what this command does. Of course this
time, <strong>localhost</strong> means <strong>jump1</strong>.
</p>

<p>
The port number on the left (in this case <strong>9822</strong>)
<i>must</i> be the same as the one on the right for the preceding
command.
</p>

<p>
Before I explain more, I'll just add one more command.
</p>

<h3>All Three Steps</h3>

<p>
By now, the last step should be obvious. (It isn't. There's one
final wrinkle.) To make the subsequent analysis easier to follow, I'll
list all three commands and then discuss.

<pre class="code">
	ssh -L 9922:localhost:9822 jump1
	ssh -L 9822:localhost:9722 jump2
	ssh -L 9722:localhost:22 target
</pre>
</p>

<div style="margin: 0px auto 10px; text-align:center" />
<a name="Diag2"></a> <img src="misc/grebler/diag_TT2_2.jpeg"
alt="Diagram 2"/>
</div>

<p>
The three commands get me to the target machine, where I can do
whatever work I need to do. That's one effect. The side-effect is more
interesting.
</p>

<p>
Quite often, when I visit a machine, I like to run several sessions,
not just a single session. To start a second session, I <i>could</i>
use a similar set of <tt>ssh</tt> commands (with or without the
<strong>-L</strong> option). Or, on my laptop, I could just go:

<pre class="code">
	ssh -p 9922 localhost
</pre>
</p>

<p>
The reference to port <strong>9922</strong> on
<strong>localhost</strong> connects me to port <strong>9822</strong>
on <strong>jump1</strong>, which automatically on-connects me to port
<strong>9722</strong> on <strong>jump2</strong>, which automatically
on-connects me to port <strong>22</strong> on <strong>jump2</strong>.
</p>

<p>
The individual tunnels combine to provide me with a "super-tunnel".
</p>

<div style="margin: 0px auto 10px; text-align:center" />
<a name="Diag3"></a> <img src="misc/grebler/diag_TT2_3.jpeg"
alt="Diagram 3"/>
</div>

<h3>Notes</h3>

<ul>
<li>
It should be easy enough to extend my example from four machines to
any arbitrary number of machines. That's not rocket science.
</li>

<li>
<p>
It should now be clear that the <tt>ssh</tt> command that gets you to
the target (the last machine), must have <strong>22</strong> as the
port number on the right of <strong>localhost</strong> in the
<strong>-L</strong> option. All the previous <tt>ssh</tt> commands are
creating "stepping-stones". The last <tt>ssh</tt> command must take
you to the real port on which the <tt>SSH</tt> daemon listens (usually
<strong>22</strong>).
</p>
</li>

<li>
<p>
As in the earlier article, the arrows in the diagram are significant:
the tunnels are unidirectional for invocation. In other words, I can
use the tunnel to get to the target from my laptop; but I can't use
<i>this</i> tunnel to get to my laptop from the target. (I'd have to do
something different if that's what I wanted. I'll leave that as an
exercise for the reader.)
</p>

<p>
That's not really very restrictive. After all, I'm doing all this work
while I'm sitting at my laptop, using its keyboard, mouse and screen.
</p>
</li>

<li>
<p>
The last point may help clarify the difference between
<strong>-L</strong> (local) and <strong>-R</strong> (remote). The
tunnel can be described as having a "mouth" at one end - the end where
it is entered. (I may have chosen an unfortunate metaphor. Let's not
concern ourselves with the other end!) On the diagrams, the arrowheads
represent the other end of each tunnel.
</p>

<p>
Thus the previous article used <strong>-R</strong> because the mouth
of the tunnel was on a remote machine (remote relative to the machine
on which the <tt>ssh</tt> command was issued); whereas this article
uses <strong>-L</strong> because, in each case, the mouth of the
tunnel is on the local machine (the machine on which the <tt>ssh</tt>
command is issued).
</p>
</li>

<li>
<p>
Arguably of even more value than being able to <tt>ssh</tt> to the
remote machine in a single command is the ability to <tt>scp</tt> (or
<tt>rsync</tt>) to and from the remote machine in a single command.
</p>

<p>
Use commands of the following form:

<pre class="code">
	scp -p -o 'port 9922' /path/to/single.file localhost:/tmp
	scp -p -o 'port 9922' localhost:/path/to/single.file /tmp

	RSYNC_RSH="ssh -o 'NoHostAuthenticationForLocalhost yes' \
		-o 'UserKnownHostsFile /dev/null' -p 9922"
	export RSYNC_RSH
	rsync -urlptog /path/to/top_dir localhost:/tmp
</pre>

</p>
</li>

<li>
It should now be clear what I meant by "unidirectional for invocation"
and why I said that that is "not really very restrictive". Yes, I have
to invoke commands on my laptop. But the copy commands of the previous
point can be used to transfer files in <i>either</i> direction (ie to
the laptop or from the laptop).
</li>

<li>
<p>
Bear in mind that the copies occur between the laptop and the target
machine in a single <i>command</i> not a single <i>step</i>. We
haven't found a magical way to bypass the intermediate machines. Under
the covers, the data goes from each machine to the adjacent machine in
the tunnel. We have only saved typing. But that's still hugely valuable.
</p>
</li>


<li>
<p>
Did anyone wonder why I kept using different port numbers?
</p>

<p>
Why did I not do this:

<pre class="code">
	ssh -L 9922:localhost:9922 jump1
</pre>

If you were going to ask this question, well spotted.
</p>

<p>
The way I have drawn the diagrams, and the way the problem originally
presented, it would have been perfectly reasonable to have all the
<strong>9X22</strong> be the same. (The <strong>22</strong> would
still have to be <strong>22</strong>.)
</p>

<p>
Because, of course, each <tt>ssh</tt> command is being issued on a
different machine, and ports only have to be unique on a single
machine (strictly, interface of a machine). [And that last little
parenthetic addition just taught me something. More later.]
</p>

<p>
It turns out that when I was attempting to <i>solve</i> the problem, I
was no longer at work. I was at home where I did not happen to have 3
spare machines available to simulate the conditions of the scenario.
</p>

<p>
Undaunted, I began to work through the problem by repeatedly
connecting back to my own machine. But this took away the premise of
an earlier paragraph: I was no longer issuing each <tt>ssh</tt>
command on a different machine. And so I had to use different port
numbers.
</p>

<p>
It does not hurt to use different port numbers; arguably, it makes the
solution more general. On the other hand there is a risk of running
out of port numbers if the chain gets ridiculously long.
</p>

<p>
It is important that the port number to the left of each
<strong>localhost</strong> (except the first) be the same as the port
number to the right of the previous <strong>localhost</strong>. So
that's an argument to keep it simple and only use one port number all
the way through (except for the final <strong>22</strong>).
</p>
</li>
</ul>

<h3>Getting there automatically</h3>

<p>
That's all you need to improve your life substantially when you
encounter a similar scenario.
</p>

<p>
What's that? You think that there is still too much typing? You want more?
</p>

<p>
Oh, all right.
</p>

<p>
Here's a fairly long <tt>expect</tt> script:

<pre>
#!/usr/local/bin/expect -f
#	ssh_tunnel.exp - ssh to a remote machine via intermediate machines

set timeout -1

	set HOSTS [list jump1 jump2 target]
	set PORTS [list 9922 9822 9722 9622 9522 9422 9322 9122 9022]

# The port of the last machine must be 22

	set jj [llength  $HOSTS]
	lset  PORTS $jj 22

	set i 0
	foreach HOST $HOSTS {
		puts "HOST= $HOST PORT= [lindex $PORTS $i]"
		set i [expr {$i + 1}]
	}

	send_user "\n"

#----------------------------------------------------------------------#
#	Procedure to get to a machine
#----------------------------------------------------------------------#

proc gotomachine {lport rport host} {
	send_user "Getting on to machine $host ... "
	send -- "ssh -L $lport:localhost:$rport $host\r"
	log_user 0
	expect -exact "Starting .bash_profile"
	expect -exact "Finished .bash_profile"
	expect -exact "-bash"
	send -- "env | grep SSH_CONNECTION\r"
	log_user 1
	send_user "done.\n"
}

#----------------------------------------------------------------------#
match_max 100000

	set dollar "$"
	spawn bash
	log_user 0
	expect -exact "-bash"
	send  -- "unset HISTFILE\r"
	expect -exact "-bash"
	send  -- "unset ignoreeof\r"
	expect -exact "-bash"
	send  -- "PS1='\nYou need one more exit to get back "
	send  -- "to where you started\nUse ^D. $ '\n"
	expect -exact "started" 
	log_user 1
	set i 0
	foreach HOST $HOSTS {
		set lport [lindex $PORTS $i]
		set i [expr {$i + 1}]
		gotomachine $lport [lindex $PORTS $i] $HOST
	}

	puts "
Houston, this is Tranquility Base. The eagle has landed. 
You should now be able to get to this machine ($HOST) directly
using:

	ssh -p [lindex $PORTS 0] localhost

To disconnect the tunnel, use the following repeatedly:
"
	puts {	[ "$SSH_CONNECTION" = '' ] || exit }
	puts "
Good luck!
"
	interact
	exit

</pre>
</p>

<h3>Notes</h3>

<ul>
<li>
To adapt this script to your situation, you need only change the list
in the first command which references HOSTS (line 6).
</li>

<li>
The script can handle up to 9 other machines (line 7). If you need
more machines, simply add entries to the first command which
references PORTS.
</li>

<li>
For more information, see expect(1).
</li>
</ul>

<h3>Tying up Loose Ends</h3>

<p>
When I developed the solution on my machine I was under the
misapprehension that I had no choice but to use different port
numbers. As I wrote this article, I said that ports only have to be
unique on a single machine - and then corrected myself and said they
only have to be unique on a single interface.
</p>

<p>
This opens the possibility of a simplification of the script
<strong>ssh_tunnel.exp</strong> - at the expense of setting up some
virtual interfaces on my single machine. If I were doing this from
scratch now, that's what I would do.

<p>
It gets very confusing constantly connecting back to a single machine.
That accounts for the large number of lines dealing with disconnecting
the tunnel. I was scared I would exit too often and blow my xterm away.
</p>

<h3>Risks and Analysis</h3>

<p>
This is a nice safe use of <tt>expect</tt>. As usual, I've set up
certificates on all relevant machines, so no paswords are necessary.
</p>

<h3>Conclusion</h3>

<p>
You should now have the tools to navigate conveniently across any
chain of machines.
</p>

<p>
Read with the previous article, this article should have given you
enough information to handle the earlier scenario without "cheating".
</p>

<p>
You should be able to extrapolate from these articles to almost any
configuration of machines.
</p>


<br clear="all" />

<table align='center' cellspacing='10'>
<tr>
<td>
<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/177/grebler.html';
digg_title = 'Tunnel Tales 2';
digg_bodytext = '<p> In a previous article, "Tunnel Tales 1", I described how to use SSH tunnels and a third machine to provide network access from one machine to a second machine which was otherwise not directly accessible. Today\'s scenario is quite different. </p> ';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>
</td>
<td>
<a name="fb_share" type="box_count" href="http://www.facebook.com/sharer.php">Share</a>
<script src="http://static.ak.fbcdn.net/connect.php/js/FB.Share" type="text/javascript"></script>
</td>
<td>
<a href="http://twitter.com/home?status=Currently%20reading:%20http://linuxgazette.net/177/grebler.html%20at%20Linux%20Gazette%20%23linuxgazette" title="Click to share this post on Twitter"><img src="../gx/twitter.png" width="50" height="85" border="0"></a>
</td>
</tr>
</table>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:177/grebler.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<hr>
<p>
<img align="left" alt="[BIO]" src="../gx/authors/grebler.jpg" class="bio">
</p>

<em>
<p>
Henry has spent his days working with computers, mostly for computer
 manufacturers or software developers. His early computer experience
 includes relics such as punch cards, paper tape and mag tape. It is
 his darkest secret that he has been paid to do the sorts of things he
 would have paid money to be allowed to do. Just don't tell any of his
 employers. 
</p>

<p>
He has used Linux as his personal home desktop since the family got its
 first PC in 1996. Back then, when the family shared the one PC, it was a
 dual-boot Windows/Slackware setup. Now that each member has his/her own
 computer, Henry somehow survives in a purely Linux world.
</p>

<p>
He lives in a suburb of Melbourne, Australia.
</p>



</em>

<br clear="all">


<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2010, <a href="../authors/grebler.html">Henry Grebler</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 177 of Linux Gazette, August 2010
</p>

</div>
</div>


<div class="content lgcontent">

<a name="hoogland"></a>
<h1>Overview: Common Linux desktops</h1>
<p id="by"><b>By <a href="../authors/hoogland.html">Jeff Hoogland</a></b></p>

</b>
</p>

<p>
<p>
Something most new Linux users often struggle to understand is the concept
of desktop environments. What a desktop environment actually is, I feel,
gets further clouded when users start exploring different "spins" of a
distro (short for distribution). For example, it is very common for a new
user to think that <span style="font-weight: bold;">K</span>ubuntu or <span
style="font-weight: bold;">X</span>ubuntu is something entirely different
from the well known <span style="font-weight: bold;">U</span>buntu. Many do
not know that they can easily install any <span style="font-weight:
bold;">*</span>buntu on any other <span style="font-weight:
bold;">*</span>buntu with a single command!<a
id="hoogland.html_1_back"></a><a href="#hoogland.html_1">[1]</a>
</p>

<p>
Just as choosing the distro can be difficult, so can choosing the
"right" desktop environment. The following is an overview of some of the best
known desktop environments so you can be more informed in your decision.
</p>

<p>
<span style="font-weight: bold;">Gnome:</span> The most popular
desktop environment currently in use is Gnome - it is the desktop
environment that powers the three most popular Linux desktop distros
(Ubuntu, Fedora, and Linux Mint). Gnome is a fully developed desktop
environment that provides a fully integrated application set. It is easy to
use and provides GUI tools for making edits to all the different features
that are available within it. It is a very "user friendly" desktop
environment that is fantastic for new users.
</p>

<p>
<img style="margin: 0px auto 10px; display: block; text-align: center; cursor:
pointer; width: 400px; height: 234px;" src="misc/hoogland/Gnome-screenshot2.jpg" border="0" />
Gnome's memory footprint is modest for all the features it provides. A default
Gnome install uses around 180megs (Mb) of RAM. If you like eye candy on your
computer, odds are you will want to run Compiz (desktop effects) on
your Gnome desktop. A default Gnome install with Compiz running uses
slightly more memory, right about 205megs.
</p>

<p>
<span style="font-weight: bold;">KDE:</span> In terms of popularity,
KDE is the second most popular desktop environment. Like Gnome, it is fully
mature and provides its own full application set as well as GUI tools for
configuration. KDE also has a wide selection of "plasma widgets", which are
handy applets you can place all around your desktop for all sorts of tasks.
They range from something as practical as a calculator to ones as useless as a
display from "The Matrix".
</p>

<p>
<img style="margin: 0px auto 10px; display: block; text-align: center; cursor:
pointer; width: 400px; height: 234px;" src="misc/hoogland/kde.png" border="0" />
Overall, 
KDE is much more customizable than Gnome, but this comes at a cost - a
default KDE install uses around 510megs of RAM. However, if you are looking for eye
candy, it does not cost as much to run KWin (KDE's built in desktop effects)
as it does to run Compiz: with KWin enabled, a default KDE install uses
around 520megs of RAM.
</p>

<p>
<span style="font-weight: bold;">XFCE:</span> XFCE is designed to
be simplistic and quick. It does not provide much in the way of eye candy
(although you can run Compiz on it), but it is a decently fast/responsive
desktop environment. While XFCE does have some of its own applications,
such as its file manager Thunar and the XFCE system monitor, it does still
borrow some applications from the Gnome environment (such as the nm-applet
network manager). Don't think XFCE is an immature project though: what it
borrows from Gnome is more to save itself from reinventing the wheel than
from a lack of ability. XFCE does not have quite as many tools for making GUI
edits as Gnome or KDE, but it does have a fairly good configuration panel.
</p>

<p>
<img style="margin: 0px auto 10px; display: block; text-align: center; cursor:
pointer; width: 400px; height: 234px;" src="misc/hoogland/xfce.png" border="0" />
Designed to be quick and lightweight, XFCE leaves a low memory footprint on
the system you have it running on. In its default state, XFCE uses around 140megs of
RAM.
</p>

<p>
<span style="font-weight: bold;">LXDE:</span> LXDE is a newer
project in the world of Linux desktop environments. Similar to XFCE, LXDE's
goal is to provide a fast, lightweight desktop environment with little
resource usage. LXDE has a few of its own applications, but those
applications it still lacks it borrows from Gnome and XFCE. The age of the
LXDE project really shows when you start to look into making customizations
to things. Many adjusts have to still be made by manually editing
configuration files - not a bad thing if you know your system well (or are
willing to learn it), but this can be a giant setback for a beginner who
wants things to "just work".
</p>

<p>
<img style="margin: 0px auto 10px; display: block; text-align: center; cursor:
pointer; width: 400px; height: 234px;" src="misc/hoogland/lxde.png" border="0" />
LXDE may be a much younger project than XFCE, but it does a fantastic job
of resource conservation. A fresh install of LXDE uses 100megs of RAM, the
lowest of all the desktop environments I am reviewing today.
</p>

<p>
<span style="font-weight: bold;">E17:</span> I cannot do an
overview of Linux desktop environments without mentioning E17. E17 is
designed to be a lightweight, but elegant desktop environment. It is very
successful at both of these tasks. E17 uses all of its own libraries, that
have been built from the ground up for speed and flexibility. E17 is a
tinkerers delight, you can customize and change anything and everything.
</p>

<p>
<img style="margin: 0px auto 10px; display: block; text-align: center; cursor:
pointer; width: 400px; height: 234px;" src="misc/hoogland/e17.png" border="0" />
A base install of E17 leaves a memory footprint of around 110megs of RAM. Now,
while a base install is functional, half the fun of E17 is in playing with
widgets, changing transitions, and generally toggling everything you can
just to see how shiny you can make your desktop. After I had my E17 fully
configured, its memory footprint was increased to a whopping 120megs of
RAM.
</p>

<p>
A few of you may be wondering if E17 is so lightweight, flexible, and
flashy, why don't more distros opt to use it for their desktop environment?
There are two reasons for this. First and foremost is the fact that E17 is
very much "beta" software. Compiling the latest version from source at any
given point can have piles of crashes/segfaults that can make using it a
giant headache. Second, if you do take the time to piece together a stable
E17 build (<a
href="http://jeffhoogland.blogspot.com/2010/03/elive-20-distro-review.html">check
out Elive</a> for the best E17 distro around), the desktop environment takes
some getting used to. For many, it will feel foreign whether they are
used to using another Linux desktop environment or a Windows machine.
</p>

<p>
<span style="font-weight: bold;">Final Thoughts:</span> All of the
various desktop environments have their advantages and their disadvantages.
Which one is right for you largely depends on your task at hand. Personally
I run LXDE on my netbook, KDE on <a
href="http://jeffhoogland.blogspot.com/2009/10/sager-notebook-powernotebookscom-review.html">my
gaming laptop</a>, and Gnome on my home media center. If you are not sure
which is best for you, try them out! It is all free software after all - get
a feel for which desktop environment you are most comfortable on and use
that one.
</p>

<p>
Is there another desktop environment that you enjoy using that I failed to
mention here? If so, let me know, I am always looking to tinker with new
things.
</p>

<hr>

<a id="hoogland.html_1"></a><a href="#hoogland.html_1_back">[1]</a>
<p>
The commands that allow you to install one version on another are:
</p>
<pre>
sudo apt-get install ubuntu-desktop
sudo apt-get install kubuntu-desktop
sudo apt-get install xubuntu-desktop
sudo apt-get install lubuntu-desktop
etc.
</pre>
<p>
You could also simply install the DE with the appropriate meta-package,
e.g.:
</p>
<pre>
sudo apt-get install kde
sudo apt-get install lxde
</pre>


<br clear="all" />

<table align='center' cellspacing='10'>
<tr>
<td>
<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/177/hoogland.html';
digg_title = 'Overview: Common Linux desktops';
digg_bodytext = '<p> Something most new Linux users often struggle to understand is the concept of desktop environments. What a desktop environment actually is, I feel, gets further clouded when users start exploring different "spins" of a distro (short for distribution). For example, it is very common for a new user to think that <span style="font-weight: bold;">K</span>ubuntu or <span style="font-weight: bold;">X</span>ubuntu is something entirely different from the well known <span style="font-weight: bold;">U</span>buntu. Many do not know that they can easily install any <span style="font-weight: bold;">*</span>buntu on any other <span style="font-weight: bold;">*</span>buntu with a single command!<a id="hoogland.html_1_back"></a>[1] </p> ';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>
</td>
<td>
<a name="fb_share" type="box_count" href="http://www.facebook.com/sharer.php">Share</a>
<script src="http://static.ak.fbcdn.net/connect.php/js/FB.Share" type="text/javascript"></script>
</td>
<td>
<a href="http://twitter.com/home?status=Currently%20reading:%20http://linuxgazette.net/177/hoogland.html%20at%20Linux%20Gazette%20%23linuxgazette" title="Click to share this post on Twitter"><img src="../gx/twitter.png" width="50" height="85" border="0"></a>
</td>
</tr>
</table>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:177/hoogland.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<hr>
<p>
<img align="left" alt="[BIO]" src="../gx/authors/hoogland.jpg" class="bio">
</p>

<em>
<p>
I am currently a full time student working my way through a math
 education program on the south side of Chicago. I work in both theatre &
 computer fields currently. I am a huge believer in Linux and believe we
 will see Microsoft's dominant market share on the personal computer
 crumble at some point in the next twenty years. I write a good deal
 about technology and you can always find my most current
 thoughts/reviews/ramblings at http://jeffhoogland.blogspot.com/
</p>



</em>

<br clear="all">


<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2010, <a href="../authors/hoogland.html">Jeff Hoogland</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 177 of Linux Gazette, August 2010
</p>

</div>
</div>


<div class="content lgcontent">

<a name="schneider"></a>
<h1>Installing Windows Server 2003 with Linux + PXE + DHCP + TFTP</h1>
<p id="by"><b>By <a href="../authors/schneider.html">Will Schneider</a></b></p>

</b>
</p>

<p>

<h3>What and why?</h3>

<p>
This procedure is for installing Windows Server 2003 over the network.
However, I believe I've invented a new way of doing a network installation
and wanted to share it with anyone who might find it useful. My quest to
install Windows with a PXE/TFTP/DHCP system started after I tinkered around
with the <a href="http://unattended.sourceforge.net">Unattended</a> package
and I found it lacking. Specifically, it's a giant hacky mess of Perl
scripts, and it only handles 32 bit Windows installs. It essentially boots
a DOS environment, creates a FAT32 partition, copies the Windows setup
files, and then reboots and converts the partition to NTFS before finishing
the install. It's a neat way of bootstrapping Windows from a Linux
environment, but when I found out that MEMDISK can boot an ISO, I had the
crazy idea of mapping an ISO image of the Windows setup CD as a RAMdisk
and running the installation from there.
</p>

<h3>Stuff You Will Need</h3>
<UL>
<LI>Enough RAM to load the full Windows setup .iso image (&gt;=1 GB is enough).
<LI>A working Linux + DHCP + PXE + TFTP server. There is a good guide to getting started <a href="http://linuxgazette.net/175/grebler.html">here</a>.
<LI>The <a href="http://www.boot-land.net/forums/index.php?showtopic=8168">winvblock</a> driver (registration required).
<LI>A VLK installation CD for Windows Server 2003. You can use Web, Std. x86, or Std. x86_64 with this guide. I haven't tested Enterprise or Data Center editions but it should be applicable to any W2K3 version.
<LI>The unpacked ISO image on your local hard disk.
<LI>Experience working with Windows installation CDs. I've used <a href="http://www.nliteos.com/">nLite</a>, <a href="http://unattended.msfn.org/unattended.xp/view/web/8/">CDimage</a>, and the <a href="http://www.microsoft.com/downloads/details.aspx?FamilyId=3E90DC91-AC56-4665-949B-BEDA3080E0F6&displaylang=en">XP SP2 Deployment Tools</a> to build my image.
<LI>Optional, but this site served as an invaluable resource for slipstreaming SP2, hotfixes, device drivers, and creating an answer file for an unattended installation. I would recommend following the guide here to prepare an unattended ISO image that you're happy with, and testing it with an actual CD-ROM before proceeding with the following steps: <a href="http://unattended.msfn.org/unattended.xp/view/web/1/">MSFN Unattended</a>.
</UL>



<h3>Getting Dirty</h3>

<p>
To make the MEMDISK-booted ISO -&gt; RAMdisk -&gt; Windows Setup chain
work, we'll need to integrate a driver into the Windows setup image that
will enable Windows to use the RAMdisk as an installation source. It's
called <a
href="http://www.boot-land.net/forums/index.php?showtopic=8168">winvblock</a>,
and it enables Windows to use a RAMdisk as a virtual block device.
</p>

<p>
To insert it into the CD, we'll need to manually modify /i386/txtsetup.sif,
the configuration file for the text mode installation portion of Windows
setup. The file is divided into separate sections with lists of definitions
in the following format:
</p>

<pre>
[Header]
definition 1
definition 2
</pre>

<p>
So, to integrate the driver add the following lines in the appropriate sections:
</p>

<pre>
[SourceDisksFiles]
wvblk32.sys = 1,,,,,,4_,4,1,,,1,4

[SCSI.Load]
wvblk32 = wvblk32.sys,4

[SCSI]
wvblk32 = "WinVBlock RAMdisk driver"
</pre>

<p>
Next, you need to compress the driver; unzip the driver pack and run the
following command at a Windows command prompt:
</p>
<pre>
makecab WVBlk32.sys WVBLK32.SY_
</pre>

<p>
Take the compressed driver and place it into the /i386 directory on the
setup disk. Note that these instructions are for a 32 bit install image,
however the 64 bit process is exactly the same, except for replacing "32"
with "64" and placing the driver/modifying txtsetup.sif in the /amd64
directory.
</p>

<p>
These modifications will allow Windows setup to install from the RAMdisk.
Now, there is one more caveat to deal with; this is the reboot after the
text mode setup when Windows boots off the local disk that has been
pre-populated with some installation files and a bootloader. Rebooting the
machine will drop the RAMdisk from memory, and we need it re-mapped to
finish the process. Dealing with this quirk is done by manipulating a
bootloader hack that resides on the Windows setup CD. The binary
/i386/BOOTFIX.BIN is the guy responsible for that annoying message that
says "press any key to boot from CD" with a time-out. If the file is
present on the disk, the message will appear. If it is removed, there is no
prompt and the CD boots immediately with no way to stop that.
</p>

<p>
There are 2 ways to handle this final quirk I've found. I'm lazy, and don't
like waiting around to press a key when the machine <b>has</b> to boot from
the CD in the first phase of setup. So I created an ISO without
BOOTFIX.BIN and called it "Stage 1". I then created a second ISO with
BOOTFIX.BIN and called it "Stage 2". On Stage 2 of the setup, you simply
load the ISO from the PXE server and let the prompt time-out, so the
machine defaults to booting from the local hard disk with the RAMdisk
loaded into memory again.
</p>

<h3>Wrapping up</h3>

<p>
At this point, the optional unattended answer file will take over and you
can grab a coffee or make fun of the guy with the giant CD book as your net
install finishes.
</p>

<p>
Finally, here are some sample entries for your PXE server (usually set up
under /tftpboot/pxelinux.cfg/default):
</p>

<pre>
label Windows 2003 Std x86 Text (stage 1)
 menu label ^Windows 2003 Std x86 Text (stage 1)
 kernel memdisk
 append raw iso
 initrd images/w2k3std_stage1.iso

label Windows 2003 Std x86 Graphical (stage 2)
 menu label ^Windows 2003 Std x86 Graphical (stage 2)
 kernel memdisk
 append raw iso
 initrd images/w2k3std_stage2.iso
</pre>

<p>
I hope that explains the process in enough detail to replicate the setup.
I've successfully installed all the i386 and amd64 flavors of Windows 2003
with this setup and I think it's a neat hack. Especially so since it's done
with all open-source tools from a Linux server. Take that, RIS/WDS!
</p>


<br clear="all" />

<table align='center' cellspacing='10'>
<tr>
<td>
<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/177/schneider.html';
digg_title = 'Installing Windows Server 2003 with Linux + PXE + DHCP + TFTP';
digg_bodytext = '<p> This procedure is for installing Windows Server 2003 over the network by using Linux. I believe I\'ve invented a new way of doing a network installation and wanted to share it with anyone who might find it useful.</p> ';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>
</td>
<td>
<a name="fb_share" type="box_count" href="http://www.facebook.com/sharer.php">Share</a>
<script src="http://static.ak.fbcdn.net/connect.php/js/FB.Share" type="text/javascript"></script>
</td>
<td>
<a href="http://twitter.com/home?status=Currently%20reading:%20http://linuxgazette.net/177/schneider.html%20at%20Linux%20Gazette%20%23linuxgazette" title="Click to share this post on Twitter"><img src="../gx/twitter.png" width="50" height="85" border="0"></a>
</td>
</tr>
</table>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:177/schneider.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<hr>
<p>
<img align="left" alt="Bio picture" src="../gx/authors/schneider.jpg" class="bio">
</p>

<em>
<p>
Will a system engineer working in the webhosting industry. He enjoys
 automating things in strange ways, or when that fails he installs Gentoo
 on it.
</p>



</em>

<br clear="all">


<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2010, <a href="../authors/schneider.html">Will Schneider</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 177 of Linux Gazette, August 2010
</p>

</div>
</div>


<div class="content lgcontent">

<a name="silva"></a>
<h1>Goodbye iPhone, Hello Palm Pre Plus</h1>
<p id="by"><b>By <a href="../authors/silva.html">Anderson Silva</a></b></p>

</b>
</p>

<p>
<p>
First, I want you to know that I am not an Apple hater. I've owned several Apple
 products over the years (since the Mac OS X era started), and I think they are 
great products (to be honest). Therefore, this is not an Apple hate-fest! My 
goal is not to make someone like or dislike one product or brand over another. 
My goal is simply to try to put in words why I've decided to try something else 
other the iPhone.
</p>

<p>
Second, I am an open source advocate, I work for an open source company, I write
 open source articles to open source publications. I believe in open source, not
 as some sort of religious belief or moral imperative but rather 
as an alternative, and I am a sucker for 'alternatives'.
</p>

<p>
An alternative way to do business, an alternative way to write code, an 
alternative way to learn, an alternative way to teach. I believe in open source.
</p>

<p>
With that said, this month I am going to share with you a little bit about 
my story of moving away from Apple's iPhone and starting to use a Linux based 
phone like the 
<a href=http://www.palm.com/us/products/phones/preplus/index.html title="Palm Pre Plus">Palm Pre Plus</a>.
</p>

<p align="center"><img src="misc/silva/pre.jpg" alt="palm pre plus" width="320" height="188">
</p>

<p>
<b>The actual story:</b>
</p>

<p>
I bought an iPhone 3G back in December 2008, mostly because my job wanted me to 
be on call for emergencies and they were going to take care of most of the bill.
 I don't talk on the phone that much and at the time I owned a Mac 
laptop, so I was very familiar with the eye candy Apple has excelled in 
presenting to their users. What I wasn't very used to was the idea of having 
Internet access anywhere I went.
</p>

<p>
I quickly became even more addicted than normal to the Internet. Waiting in 
lines or at the doctor's office was not an issue anymore because I could check 
my email, use Twitter or Facebook, and even get work done all through my phone. 
I am not going to debate with anyone if this constant access to the Internet is 
a good thing or not. I happen to believe that like most things in life it has 
its advantages and disadvantages.
</p>

<p>
Twelve months went by, and my iPhone became the one item in my life that I had 
within my reach virtually 24/7.
</p>
  
<p>
In December 2009, I decided to upgrade, this time using my own funds. I got the 
iPhone 3Gs, and was very pleased with the upgrades in memory, bump in storage 
and camera quality that Apple provided with the product.
</p>

<p>
So, what changed for me to want to change phones?
</p>

<p>
Well, it hasn't been one specific problem, but a collection of events. I started 
hearing Steve Jobs trash Adobe, and letting everyone know how 'open' Apple is. 
Really? <em>Open?</em>
</p>

<p>
I could probably write pages upon pages about the issues I have with Apple's 
'open' practices: not allowing users to directly manipulate their music files on
 the iPhone/iPod, or banning other languages/IDEs from writing apps to the 
iPhone/iPod (I think I heard that was overturned, maybe not), selling music with
 DRM and then charging extra to free the music, putting out 'HTML5' sample pages
 that only work with their own browser, a phone that only works on 1 US provider, and
 God forbid if you try to 'hack' your way into getting the phone working the way 
you'd like, they will release updates just to break your 'hack'. That just 
doesn't sound that open to me.
</p>

<p class="editorial">
[ Late-breaking news from this article's author: as of last week, it is
<a href="http://apple.slashdot.org/story/10/07/26/1552249/Jailbreaking-iPhone-Now-Legal?art_pos=1">
legal to jailbreak your iPhone</a>. Despite this, however, I agree with his
original premise and believe that it still stands without any modification:
Apple's practices cannot be accurately described as "open". -- Ben Okopnik ]
</p>

<p>
Then came the news that Apple's market value passed Microsoft's - which,
honestly, doesn't make much sense to me. Microsoft is everywhere, not just
everywhere here in the U.S., they are literally everywhere around the
world with Windows (desktops and servers), Office, MS SQL, XBox, Visual
Studio, Sharepoint - they even provide the ECUs for Formula 1! In
comparison, where is Apple? Mostly concentrated in the US, in a few
desktops and notebooks, quite a lot of phones and MP3 players, but does
that make Apple worth more than Microsoft? I am not an economist, and I am
sure there is an explanation to all of this, but when I look around with my
'binary' perspective of either 'on' or 'off', I don't get it.  It's hard to
believe that a company that was mostly bankrupt in 1998 has surpassed
Microsoft.
</p>

<p>
Then in June of 2010, tech media outlets around the world were speculating
about what Apple would release at the WWDC besides the iPhone 4, which a lot
of us found out about from the drunk guy that left one in a bar 3 months or
so ago. Well, the WWDC came, and Steve Jobs showed to the world why Apple
has bypassed Microsoft: presentation.
</p>
  
<p>
Steve Jobs presented 2 full hours on the iPhone 4 (and iOS4) without introducing
 anything else new. The iPhone 4 is cool, don't get me wrong, and to be honest, 
there are other phones out there that are just as good or better than the iPhone
 4 hardware-wise, but when you add the usability of iOS and the iPhone it 
becomes quite the compelling combination to the masses.
</p>

<p>
On June 15th, the day pre-orders opened for the iPhone 4, I was up at 6 AM, and 
pretty much tried all day to pre-order 2 iPhones, one for me and one for my 
wife, without much success.
</p>

<p>
What bothered me the most was that Apple made 'reserving' an iPhone a mostly 
pain free process, but I wanted to pre-order one so it would be delivered at 
my doorstep. I did not want to go stand in line to pick it up at the store. 
For over 12 hours, Apple left 2 buttons on their web site: Pre-Order and 
Reserve. The 'Reserve' seemed to work, but the 'Pre-Order' didn't.
</p>

<p>
That's when I made my decision... How arrogant can a brand/company be to 
knowingly put out a 'broken' button (and yes, I understand it was due to 
heavy volume) on their page without any warning, notice, or press release to 
their customers? Has Apple become just a big technological drug dealer selling 
'goods' to millions of junkies?
</p>

<p>
Well, I don't want to be part of that dance any longer.
</p>

<p>
The other alternative was to just pay a termination fee and jump to Verizon
 or Sprint to get an Android phone like the 
<a href=http://now.sprint.com/firsts/evo4g/ id=smw2 title="HTC Evo">HTC Evo</a> 
or <a href=http://www.motorola.com/Consumers/US-EN/Consumer-Product-and-Services/Mobile-Phones/Motorola-DROID-X-US-EN?localeId=33 id=pb5- title="Motorola Droid X">Motorola Droid X</a>, 
but that would again fall outside of my budget because my wife would stay under 
AT&amp;T with her new iPhone, and I wouldn't be able to use a family plan for 
our phones. That's when I discovered that AT&amp;T was now carrying the Palm Pre
 Plus, which runs the Linux based 
<a href=http://en.wikipedia.org/wiki/WebOS id=izs. title=webOS>webOS</a>. 
I decided to buy the phone even though there was an existing risk of buying a 
device from a company that has been recently acquired by HP. What would happen 
to support? What would happen to future WebOS releases?
</p>

<p>
Since that time, HP announced that it intends to use WebOS in future
versions of its devices like smartphones and tablet PCs.
</p>

<p>
As of the writing of this article, I've owned my Palm Pre Plus for about 17
days, and overall I am a bit disappointed with the hardware, but very
satisfied with WebOS. The multitasking capabilities are fantastic, although
it clearly affects the battery life on the device, which compared to the
iPhone is very poor. I like the fact that I can mount my device on my
Fedora Linux laptop, drop MP3s files into the Music directory, and it just
plays. The package management tool <a href=http://www.preware.org id=xmx9
title=Preware>Preware</a> is another great advantage of this phone, which
lets you install unofficial apps, including WebOS patches,
and even overclock your phone; not advised by Palm, yet it works pretty
well so far.
</p>

<p>
In closing, I think WebOS has a lot of potential and I can't wait to see
what HP is going to do with it. The phone itself has been a bit of a
disappointment, but not enough for me to regret getting one, but I
sincerely hope the new versions put out by HP/Palm will resolve some of the
issues I've found so far.
</p>


<br clear="all" />

<table align='center' cellspacing='10'>
<tr>
<td>
<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/177/silva.html';
digg_title = 'Goodbye iPhone, Hello Palm Pre Plus';
digg_bodytext = '<p> First, I want you to know that I am not an Apple hater. I\'ve owned several Apple  products over the years (since the Mac OS X era started), and I think they are  great products (to be honest). Therefore, this is not an Apple hate-fest! My  goal is not to make someone like or dislike one product or brand over another.  My goal is simply to try to put in words why I\'ve decided to try something else  other the iPhone. </p> ';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>
</td>
<td>
<a name="fb_share" type="box_count" href="http://www.facebook.com/sharer.php">Share</a>
<script src="http://static.ak.fbcdn.net/connect.php/js/FB.Share" type="text/javascript"></script>
</td>
<td>
<a href="http://twitter.com/home?status=Currently%20reading:%20http://linuxgazette.net/177/silva.html%20at%20Linux%20Gazette%20%23linuxgazette" title="Click to share this post on Twitter"><img src="../gx/twitter.png" width="50" height="85" border="0"></a>
</td>
</tr>
</table>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:177/silva.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<hr>
<p>
<img align="left" alt="[BIO]" src="../gx/authors/silva.jpg" class="bio">
</p>

<em>
<p>
Anderson Silva works as an IT Release Engineer at Red Hat, Inc. He holds a
BS in Computer Science from Liberty University, a MS in Information Systems
from the University of Maine. He is a Red Hat Certified Architect and has
authored several Linux based articles for publications like: Linux Gazette,
Revista do Linux, and Red Hat Magazine. Anderson has been married to his
High School sweetheart, Joanna (who helps him edit his articles before
submission), for 11 years, and has 3 kids. When he is not working or
writing, he enjoys photography, spending time with his family,  road
cycling, watching Formula 1 and Indycar races, and taking his boys karting,
</p>

</em>

<br clear="all">


<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2010, <a href="../authors/silva.html">Anderson Silva</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 177 of Linux Gazette, August 2010
</p>

</div>
</div>


<div class="content lgcontent">

<a name="collinge"></a>
<h1>HelpDex</h1>
<p id="by"><b>By <a href="../authors/collinge.html">Shane Collinge</a></b></p>

</b>
</p>

<p>

<p>
<em>These images are scaled down to minimize horizontal scrolling.</em>
</p>

<a href="http://linuxgazette.net/124/misc/nottag/flash.html"><b>Flash problems?</b></a>
<br>

<div class="cartoon">

<object>
<embed src="misc/collinge/061promotion.swf" bgcolor="#ffffff" width="600" />
</object>

<p>
<a href="misc/collinge/061promotion.swf">Click here to see the full-sized image</a>
</p>

</div>
<div class="cartoon">

<object>
<embed src="misc/collinge/062zero.swf" bgcolor="#ffffff" width="600" />
</object>

<p>
<a href="misc/collinge/062zero.swf">Click here to see the full-sized image</a>
</p>

</div>
<div class="cartoon">

<object>
<embed src="misc/collinge/064beepboop.swf" bgcolor="#ffffff" width="600" />
</object>

<p>
<a href="misc/collinge/064beepboop.swf">Click here to see the full-sized image</a>
</p>

</div>
<div class="cartoon">

<object>
<embed src="misc/collinge/065y2k.swf" bgcolor="#ffffff" width="600" />
</object>

<p>
<a href="misc/collinge/065y2k.swf">Click here to see the full-sized image</a>
</p>

</div>
<div class="cartoon">

<object>
<embed src="misc/collinge/066specifics.swf" bgcolor="#ffffff" width="600" />
</object>

<p>
<a href="misc/collinge/066specifics.swf">Click here to see the full-sized image</a>
</p>

</div>

<p> All HelpDex cartoons are at Shane's web site,
<a href="http://www.shanecollinge.com/">www.shanecollinge.com</a>.

<script src="http://www.google-analytics.com/urchin.js"
type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-1204316-1";
urchinTracker();
</script>


</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:177/collinge.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<!-- *** BEGIN bio *** -->
<hr>
<P>
<img ALIGN="LEFT" ALT="Bio picture" SRC="../gx/2002/note.png" class="bio">
<em>
Part computer programmer, part cartoonist, part Mars Bar. At night, he runs
around in his brightly-coloured underwear fighting criminals. During the
day... well, he just runs around in his brightly-coloured underwear. He
eats when he's hungry and sleeps when he's sleepy.
</em>
<br CLEAR="all">
<!-- *** END bio *** -->

<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2010, <a href="../authors/collinge.html">Shane Collinge</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 177 of Linux Gazette, August 2010
</p>

</div>
</div>


<div class="content lgcontent">

<a name="xkcd"></a>
<h1>XKCD</h1>
<p id="by"><b>By <a href="../authors/munroe.html">Randall Munroe</a></b></p>

</b>
</p>

<p>

<p>

<div class="cartoon1">
<a href="misc/xkcd/frogger.png">
<img alt="[cartoon]" title="I understand you and your team worked hard on this, but when we said to make it more realistic, we meant the graphics.
" src="misc/xkcd/frogger.png">
<br />Click here to see the full-sized image
</a>
</div>

More XKCD cartoons can be found
<a href="http://xkcd.com">here</a>.


<script src="http://www.google-analytics.com/urchin.js"
type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-1204316-1";
urchinTracker();
</script>


</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:177/xkcd.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<hr>
<p>
<img align="left" alt="[BIO]" src="../gx/2002/note.png" class="bio">
</p>

<em>
<p>
I'm just this guy, you know? I'm a CNU graduate with a degree in
 physics. Before starting xkcd, I worked on robots at NASA's Langley
 Research Center in Virginia. As of June 2007 I live in Massachusetts. In
 my spare time I climb things, open strange doors, and go to goth clubs
 dressed as a frat guy so I can stand around and look terribly
 uncomfortable. At frat parties I do the same thing, but the other way
 around.
</p>
</em>

<br clear="all">


<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2010, <a href="../authors/munroe.html">Randall Munroe</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 177 of Linux Gazette, August 2010
</p>

</div>
</div>


<div class="content lgcontent">

<a name="doomed"></a>
<h1>Doomed to Obscurity</h1>
<p id="by"><b>By <a href="../authors/trbovich.html">Pete Trbovich</a></b></p>

</b>
</p>

<p>

<p>
<em>These images are scaled down to minimize horizontal scrolling.</em>
</p>

<div class="cartoon">

<p>
<a href="misc/doomed/0000293.jpg">
<img src="misc/doomed/0000293.jpg" bgcolor="#ffffff" width="600" border="none" />
<br /> Click here to see the full-sized image
</a>
</p>

</div>
<div class="cartoon">

<p>
<a href="misc/doomed/0000292.jpg">
<img src="misc/doomed/0000292.jpg" bgcolor="#ffffff" width="600" border="none" />
<br /> Click here to see the full-sized image
</a>
</p>

</div>

<p> All "Doomed to Obscurity" cartoons are at Pete Trbovich's site,
<a
href="http://penguinpetes.com/Doomed_to_Obscurity/">http://penguinpetes.com/Doomed_to_Obscurity/</a>.

<script src="http://www.google-analytics.com/urchin.js"
type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-1204316-1";
urchinTracker();
</script>


</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:177/doomed.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<hr>
<p>
<img align="left" alt="[BIO]" src="../gx/2002/note.png" class="bio">
</p>

<em>
<p>
Born September 22, 1969, in Gardena, California, "Penguin" Pete Trbovich
 today resides in Iowa with his wife and children. Having worked various
 jobs in engineering-related fields, he has since "retired" from
 corporate life to start his second career. Currently he works as a
 freelance writer, graphics artist, and coder over the Internet. He
 describes this work as, "I sit at home and type, and checks mysteriously
 arrive in the mail."
</p>

<p>
He discovered Linux in 1998 - his first distro was Red Hat 5.0 - and has
 had very little time for other operating systems since. Starting out
 with his freelance business, he toyed with other blogs and websites
 until finally getting his own domain penguinpetes.com started in March
 of 2006, with a blog whose first post stated his motto: "If it isn't fun
 for me to write, it won't be fun to read."
</p>

<p>
The webcomic <em>Doomed to Obscurity</em> was launched New Year's Day,
 2009, as a "New Year's surprise". He has since rigorously stuck to a
 posting schedule of "every odd-numbered calendar day", which allows him
 to keep a steady pace without tiring. The tagline for the webcomic
 states that it "gives the geek culture just what it deserves." But is it
 skewering everybody but the geek culture, or lampooning geek culture
 itself, or doing both by turns?
</p>



</em>

<br clear="all">


<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2010, <a href="../authors/trbovich.html">Pete Trbovich</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 177 of Linux Gazette, August 2010
</p>

</div>
</div>


<img src="../gx/tux_86x95_indexed.png" id="tux" alt="Tux"/>

<br />

<script src="http://www.google-analytics.com/urchin.js"
type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-1204316-1";
urchinTracker();
</script>

</body>
</html>

